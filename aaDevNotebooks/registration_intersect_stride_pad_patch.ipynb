{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *get_fence_array(patch_length, overall_length)* revisited\n",
    "```python\n",
    "def get_fence_array_from_padded_segment_with_stride(patch_len, start_seg, end_seg, fill_complete=False):\n",
    "    \n",
    "    return fence_array\n",
    "```\n",
    "\n",
    "## Compare padding vs stride in the context of registration intersection pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 344) (340, 284)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def check_patch_in_bounds(x, y, X_dim, Y_dim):\n",
    "    \"\"\" Usage: TrueFalse = check_patch_in_bounds(x, y, X_dim, Y_dim)\n",
    "                determine if the box is within the image\n",
    "    Args:\n",
    "        x:               a tuple, list or array (x_start, x_end)\n",
    "        y:               a tuple, list or array (y_start, Y_end)\n",
    "        X_dim:           a tuple, list or array (Image_X_start, Image_X_end)\n",
    "        Y_dim:           a tuple, list or array (Image_Y_start, Image_Y_end)\n",
    "    \"\"\"\n",
    "    if x[0] > x[1] or y[0] > y[1] or X_dim[0] > X_dim[1] or Y_dim[0] > Y_dim[1]:\n",
    "        return False\n",
    "    \n",
    "    if x[0] >= X_dim[0] and y[0] >= Y_dim[0] and x[1] < X_dim[1] and y[1] < Y_dim[1]:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def im_pair_hori(im_0, im_1):\n",
    "    \"\"\" Usage: new_im = im_pair_hori(im_0, im_1)\n",
    "            combine a list of PIL images horizontaly\n",
    "    \"\"\"\n",
    "    w0 = im_0.size[0]\n",
    "    w = w0 + im_1.size[0] + 1\n",
    "    h = max(im_0.size[1], im_1.size[1])\n",
    "\n",
    "    new_im = tip.Image.new('RGB', (w, h) )\n",
    "    box = (0, 0, w0, h)\n",
    "    new_im.paste(im_0, box)\n",
    "    \n",
    "    box = (w0+1, 0, w, h)\n",
    "    new_im.paste(im_1, box)\n",
    "\n",
    "    return new_im\n",
    "\n",
    "X_dim, Y_dim = (120, 1193), (59, 1200)\n",
    "x = (120 + 25, 344)\n",
    "y = (60+280, 284)\n",
    "print(x, y)\n",
    "x = list(x)\n",
    "y = np.array(y)\n",
    "check_patch_in_bounds(x, y, X_dim, Y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (0, 10)\n",
    "X = (0, 10)\n",
    "x and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_length 224 start_segment 22 end_segment 2500\n",
      "\n",
      "overall_length: 2478\n",
      "stride 207 n_fenced * stride 2484\n",
      "Array Size =  12\n",
      "\n",
      "[ 22 245] \t223\n",
      "[229 452] \t223\n",
      "[436 659] \t223\n",
      "[643 866] \t223\n",
      "[ 850 1073] \t223\n",
      "[1057 1280] \t223\n",
      "[1264 1487] \t223\n",
      "[1471 1694] \t223\n",
      "[1678 1901] \t223\n",
      "[1885 2108] \t223\n",
      "[2092 2315] \t223\n",
      "[2276 2499] \t223\n"
     ]
    }
   ],
   "source": [
    "def get_strided_fence_array_NB(patch_length, start_seg, end_seg):\n",
    "    \"\"\" Usage: fence_array = get_fence_array(patch_length, overall_length)\n",
    "        create a left-right set of pairs that descrete overall_length into patch_length segments\n",
    "\n",
    "    Args:\n",
    "        patch_length:   patch size - number of pixels high or wide\n",
    "        patch_length:   overall number of pixels high or wide\n",
    "\n",
    "    Returns:\n",
    "        fence_array:    boundry values for each segment\n",
    "        -----------:    [[left_0, right_0],\n",
    "                         [left_1, right_1],\n",
    "                         [left_2, right_2],... ]\n",
    "    \"\"\"\n",
    "    #                               determine the stride:\n",
    "    overall_length = end_seg - start_seg\n",
    "    n_fenced = np.ceil(overall_length / patch_length).astype(int)  # number of boxes\n",
    "    stride = np.ceil(overall_length / n_fenced).astype(int)\n",
    "    \n",
    "    #                               initialize the return array:\n",
    "    fence_array = np.zeros((n_fenced, 2)).astype(int)\n",
    "    \n",
    "    #                               fill in the beginning pair:\n",
    "    fence_array[0,0] = start_seg\n",
    "    fence_array[0,1] = start_seg + patch_length - 1\n",
    "    \n",
    "    #                               fill in the rest, including the last:\n",
    "    for k in range(1, fence_array.shape[0]):    \n",
    "        fence_array[k, 0] = fence_array[k-1, 0] + stride\n",
    "        fence_array[k, 1] = fence_array[k, 0] + patch_length - 1\n",
    "        \n",
    "    #                               re-fill in the last one measured from the end:\n",
    "    fence_array[k, 1] = end_seg - 1\n",
    "    fence_array[k, 0] = end_seg - patch_length\n",
    "    \n",
    "    return fence_array\n",
    "\n",
    "patch_length = 224\n",
    "remainder = 23\n",
    "overall_length = 224*12 + remainder\n",
    "start_seg = 22\n",
    "end_seg = overall_length - 211\n",
    "\n",
    "print('patch_length', patch_length, 'start_segment', start_seg, 'end_segment %i\\n'%(end_seg))\n",
    "fa = get_strided_fence_array_NB(patch_length, start_seg, end_seg)\n",
    "print('Array Size =  %i\\n'%(len(fa)))\n",
    "for f in fa:\n",
    "    print(f, '\\t%i'%(f[1] - f[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# patch_length 224 overall_length 2711 remainder 23\n",
    "\n",
    "[ 12 235]\n",
    "[236 459]\n",
    "[460 683]\n",
    "[684 907]\n",
    "[ 908 1131]\n",
    "[1132 1355]\n",
    "[1356 1579]\n",
    "[1580 1803]\n",
    "[1804 2027]\n",
    "[2028 2251]\n",
    "[2252 2475]\n",
    "[2476 2699]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_length 224 overall_length 2711 remainder 23\n",
      "\n",
      "Array Size =  12\n",
      "\n",
      "[ 12 235] \t223\n",
      "[236 459] \t223\n",
      "[460 683] \t223\n",
      "[684 907] \t223\n",
      "[ 908 1131] \t223\n",
      "[1132 1355] \t223\n",
      "[1356 1579] \t223\n",
      "[1580 1803] \t223\n",
      "[1804 2027] \t223\n",
      "[2028 2251] \t223\n",
      "[2252 2475] \t223\n",
      "[2476 2699] \t223\n"
     ]
    }
   ],
   "source": [
    "# patch_length 224 overall_length 2711 remainder 23\n",
    "\n",
    "def get_fence_array_NB(patch_length, overall_length):\n",
    "    \"\"\" Usage: fence_array = get_fence_array(patch_length, overall_length)\n",
    "        create a left-right set of pairs that descrete overall_length into patch_length segments\n",
    "\n",
    "    Args:\n",
    "        patch_length:   patch size - number of pixels high or wide\n",
    "        patch_length:   overall number of pixels high or wide\n",
    "\n",
    "    Returns:\n",
    "        fence_array:    boundry values for each segment\n",
    "        -----------:    [[left_0, right_0],\n",
    "                         [left_1, right_1],\n",
    "                         [left_2, right_2],... ]\n",
    "    \"\"\"\n",
    "    # Determine the array size\n",
    "    n_fenced = overall_length // patch_length  # number of boxes\n",
    "    n_remain = 1 + overall_length % patch_length  # number of pixels leftover\n",
    "    paddit = n_remain // 2  # padding for the beginning\n",
    "\n",
    "    if n_remain == patch_length:  # exact fit special case: exactly one left over\n",
    "        paddit = 0\n",
    "        n_fenced = n_fenced + 1\n",
    "\n",
    "    # Allocate as integers for use as indices\n",
    "    fence_array = np.zeros((n_fenced, 2)).astype(int)\n",
    "    for k in range(n_fenced):\n",
    "        # for each box edge, get the beginning and end pixel location\n",
    "        if k == 0:\n",
    "            # first case special (padding)\n",
    "            fence_array[k, 0] = paddit\n",
    "            # add the width to it\n",
    "            fence_array[k, 1] = fence_array[k, 0] + patch_length - 1\n",
    "\n",
    "        elif fence_array[k - 1, 1] + patch_length <= overall_length:\n",
    "            # Previous right pixel plus one\n",
    "            fence_array[k, 0] = fence_array[k - 1, 1] + 1\n",
    "            # add the width to it\n",
    "            fence_array[k, 1] = fence_array[k, 0] + patch_length - 1\n",
    "\n",
    "    return fence_array\n",
    "\n",
    "print('patch_length', patch_length, 'overall_length', overall_length, 'remainder %i\\n'%(remainder))\n",
    "fa_old = get_fence_array_NB(patch_length, overall_length)\n",
    "print('Array Size =  %i\\n'%(len(fa_old)))\n",
    "for f0 in fa_old:\n",
    "    print(f0, '\\t%i'%(f0[1] - f0[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "nb_start_time = time.time()\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openslide\n",
    "\n",
    "sys.path.insert(0, '../src/python')\n",
    "from digipath_toolkit import get_level_sizes_dict, get_sample_selection_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "offset_x, offset_y, auto_x, auto_y\n",
      " -1618 1673 -1621 1676\n",
      "\n",
      "\n",
      "fixed_wsi image: 54742d6c5d704efa8f0814456453573a.tiff\n",
      "               image_size: (145408, 83968)\n",
      "              level_count: 10\n",
      "        level_downsamples: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0)\n",
      "         level_diminsions: ((145408, 83968), (72704, 41984), (36352, 20992), (18176, 10496), (9088, 5248), (4544, 2624), (2272, 1312), (1136, 656), (568, 328), (284, 164))\n",
      "\n",
      "\n",
      "float_wsi image: e39a8d60a56844d695e9579bce8f0335.tiff\n",
      "               image_size: (126976, 75776)\n",
      "              level_count: 9\n",
      "        level_downsamples: (1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0)\n",
      "         level_diminsions: ((126976, 75776), (63488, 37888), (31744, 18944), (15872, 9472), (7936, 4736), (3968, 2368), (1984, 1184), (992, 592), (496, 296))\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = '../../DigiPath_MLTK_data/RegistrationDevData/'\n",
    "os.listdir(test_data_dir)\n",
    "\n",
    "offset_data_file = os.path.join(test_data_dir, 'wsi_pair_sample.csv')\n",
    "if os.path.isfile(offset_data_file):\n",
    "    offset_df = pd.read_csv(offset_data_file)\n",
    "    \n",
    "offset_x = offset_df['truth_offset_x'].iloc[0]\n",
    "offset_y = offset_df['truth_offset_y'].iloc[0]\n",
    "offset_x, offset_y = int(round(offset_x)), int(round(offset_y))\n",
    "\n",
    "auto_x = offset_df['auto_offset_x'].iloc[0]\n",
    "auto_y = offset_df['auto_offset_y'].iloc[0]\n",
    "auto_x, auto_y = int(round(auto_x)), int(round(auto_y))\n",
    "\n",
    "print('\\noffset_x, offset_y, auto_x, auto_y\\n', offset_x, offset_y, auto_x, auto_y)\n",
    "\n",
    "fixed_wsi = os.path.join(test_data_dir, '54742d6c5d704efa8f0814456453573a.tiff')\n",
    "\n",
    "fixed_levels_dict = get_level_sizes_dict(fixed_wsi)\n",
    "fixed_max_width = fixed_levels_dict['image_size'][0]\n",
    "fixed_max_height = fixed_levels_dict['image_size'][1]\n",
    "\n",
    "print('\\n\\nfixed_wsi image: 54742d6c5d704efa8f0814456453573a.tiff')\n",
    "for k, v in fixed_levels_dict.items():\n",
    "    print('%25s: %s'%(k,v))\n",
    "    \n",
    "float_wsi = os.path.join(test_data_dir, 'e39a8d60a56844d695e9579bce8f0335.tiff')\n",
    "\n",
    "float_levels_dict = get_level_sizes_dict(float_wsi)\n",
    "float_max_width = float_levels_dict['image_size'][0]\n",
    "float_max_height = float_levels_dict['image_size'][1]\n",
    "\n",
    "print('\\n\\nfloat_wsi image: e39a8d60a56844d695e9579bce8f0335.tiff')\n",
    "for k, v in float_levels_dict.items():\n",
    "    print('%25s: %s'%(k,v))\n",
    "    \n",
    "run_parameters = {'wsi_filename': fixed_wsi, \n",
    "                  'wsi_floatname': float_wsi,\n",
    "                  'thumbnail_divisor': 20, \n",
    "                  'patch_select_method': 'threshold_rgb2lab', \n",
    "                  'rgb2lab_threshold': 80, \n",
    "                  'image_level': 0, \n",
    "                  'patch_height': 224, \n",
    "                  'patch_width': 224, \n",
    "                  'threshold': 0, \n",
    "                  'offset_x': offset_x, \n",
    "                  'offset_y': offset_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_length: 83968\n",
      "stride 224 n_fenced * stride 84000\n",
      "overall_length: 145408\n",
      "stride 224 n_fenced * stride 145600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55966"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_patch_location_array_for_image_level_NB(run_parameters):\n",
    "    \"\"\" Usage: patch_location_array = get_patch_location_array_for_image_level(run_parameters)\n",
    "        using 'patch_select_method\", find all upper left corner locations of patches\n",
    "        that won't exceed image size givin the 'patch_height' and 'patch_width'\n",
    "\n",
    "    Args (run_parameters):  python dict.keys()\n",
    "                                wsi_filename:           file name (with valid path)\n",
    "                                patch_height:           patch size = (patch_width, patch_height)\n",
    "                                patch_width:            patch size = (patch_width, patch_height)\n",
    "                                thumbnail_divisor:      wsi_image full size divisor to create thumbnail image\n",
    "                                patch_select_method:    'threshold_rgb2lab' or 'threshold_otsu'\n",
    "                                threshold:              minimimum sum of thresholded image (default = 0)\n",
    "                                image_level:            openslide image pyramid level 0,1,2,...\n",
    "    Returns:\n",
    "        patch_location_array\n",
    "\n",
    "    \"\"\"\n",
    "    #                   initialize an empty return value\n",
    "    patch_location_array = []\n",
    "    #                   name the input variables\n",
    "    wsi_filename = run_parameters['wsi_filename']\n",
    "    thumbnail_divisor = run_parameters['thumbnail_divisor']\n",
    "    patch_select_method = run_parameters['patch_select_method']\n",
    "    patch_height = run_parameters['patch_height']\n",
    "    patch_width = run_parameters['patch_width']\n",
    "    #                   set defaults for newly added parameters\n",
    "    if 'threshold' in run_parameters:\n",
    "        threshold = run_parameters['threshold']\n",
    "    else:\n",
    "        threshold = 0\n",
    "\n",
    "    if 'image_level' in run_parameters:\n",
    "        image_level = run_parameters['image_level']\n",
    "    else:\n",
    "        image_level = 0\n",
    "\n",
    "    #                     OpenSlide open                      #\n",
    "    os_im_obj = openslide.OpenSlide(wsi_filename)\n",
    "    obj_level_diminsions = os_im_obj.level_dimensions\n",
    "\n",
    "    #                   get the start, stop locations list for the rows\n",
    "    pixels_height = obj_level_diminsions[image_level][1]\n",
    "    start_row = 0\n",
    "    rows_fence_array = get_strided_fence_array_NB(patch_height, start_row, pixels_height)\n",
    "\n",
    "    #                   get the start, stop locations list for the columns\n",
    "    pixels_width = obj_level_diminsions[image_level][0]\n",
    "    start_col = 0\n",
    "    cols_fence_array = get_strided_fence_array_NB(patch_width, start_col, pixels_width)\n",
    "\n",
    "    #                   get a thumbnail image for the patch select method\n",
    "    thumbnail_size = (pixels_width // thumbnail_divisor, pixels_height // thumbnail_divisor)\n",
    "    small_im = os_im_obj.get_thumbnail(thumbnail_size)\n",
    "    os_im_obj.close()\n",
    "    #                     OpenSlide close                     #\n",
    "\n",
    "    #                   get the binary mask as a measure of image region content\n",
    "    mask_im = get_sample_selection_mask(small_im, patch_select_method)\n",
    "\n",
    "    #                   iterator for rows:  (top_row, bottom_row, full_scale_row_number)\n",
    "    it_rows = zip(rows_fence_array[:, 0] // thumbnail_divisor,\n",
    "                  rows_fence_array[:, 1] // thumbnail_divisor,\n",
    "                  rows_fence_array[:, 0])\n",
    "\n",
    "    #                   variables for columns iterator\n",
    "    lft_cols = cols_fence_array[:, 0] // thumbnail_divisor\n",
    "    rgt_cols = cols_fence_array[:, 1] // thumbnail_divisor\n",
    "    cols_array = cols_fence_array[:, 0]\n",
    "\n",
    "    for tmb_row_top, tmb_row_bot, row_n in it_rows:\n",
    "        #               iterator for cols:  (left_column, right_column, full_scale_column_number)\n",
    "        it_cols = zip(lft_cols, rgt_cols, cols_array)\n",
    "\n",
    "        for tmb_col_lft, tmb_col_rgt, col_n in it_cols:\n",
    "\n",
    "            #           if the sum of the mask elements is larger than the threshold...\n",
    "            if (mask_im[tmb_row_top:tmb_row_bot, tmb_col_lft:tmb_col_rgt]).sum() > threshold:\n",
    "\n",
    "                #       add the full scale row and column of the upper left corner to the list\n",
    "                patch_location_array.append((row_n, col_n))\n",
    "\n",
    "    return patch_location_array\n",
    "\n",
    "patch_location_array = get_patch_location_array_for_image_level_NB(run_parameters)\n",
    "\n",
    "len(patch_location_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsi_filename ../../DigiPath_MLTK_data/RegistrationDevData/54742d6c5d704efa8f0814456453573a.tiff\n",
      "wsi_floatname ../../DigiPath_MLTK_data/RegistrationDevData/e39a8d60a56844d695e9579bce8f0335.tiff\n",
      "thumbnail_divisor 20\n",
      "patch_select_method threshold_rgb2lab\n",
      "rgb2lab_threshold 80\n",
      "image_level 0\n",
      "patch_height 224\n",
      "patch_width 224\n",
      "threshold 0\n",
      "offset_x -1618\n",
      "offset_y 1673\n",
      "\n",
      "            key_name:\n",
      "(fixed values)\n",
      "(float values)\n",
      "\n",
      "          image_size:\n",
      "(145408, 83968)\n",
      "(126976, 75776)\n",
      "\n",
      "         level_count:\n",
      "10\n",
      "9\n",
      "\n",
      "   level_downsamples:\n",
      "(1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0)\n",
      "(1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0)\n",
      "\n",
      "    level_diminsions:\n",
      "((145408, 83968), (72704, 41984), (36352, 20992), (18176, 10496), (9088, 5248), (4544, 2624), (2272, 1312), (1136, 656), (568, 328), (284, 164))\n",
      "((126976, 75776), (63488, 37888), (31744, 18944), (15872, 9472), (7936, 4736), (3968, 2368), (1984, 1184), (992, 592), (496, 296))\n"
     ]
    }
   ],
   "source": [
    "for k, v in run_parameters.items():\n",
    "    print(k,v)\n",
    "    \n",
    "print('\\n%20s:'%('key_name'))\n",
    "print('(fixed values)')\n",
    "print('(float values)')\n",
    "\n",
    "for k, v in fixed_levels_dict.items():\n",
    "    print('\\n%20s:'%(k))\n",
    "    print(v)\n",
    "    print(float_levels_dict[k])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
