{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety Parse XML - *get_label_coords_dict(xml_file_name)*:\n",
    "[python docs: xml module warning ](https://docs.python.org/3/library/xml.html#defused-packages) <br>\n",
    "[defusexml - risks exhibit](https://pypi.org/project/defusedxml/) <br>\n",
    "****\n",
    "python library xml has unacceptable vulnerabilities ergo here parse the file as text - else fail (w no risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import defaultdict, OrderedDict\n",
    "import json\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openslide\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "py_src_code_dir = '../src/python'\n",
    "sys.path.insert(0, py_src_code_dir)\n",
    "from digipath_toolkit import get_sample_selection_mask, get_strided_fence_array\n",
    "from digipath_toolkit import get_patch_location_array_for_image_level\n",
    "\n",
    "data_dir = '../../DigiPath_MLTK_data'\n",
    "zip_tank = '../../DigiPath_MLTK_data/zipTank/wsi_annotation_sample/'\n",
    "xml_name = os.path.join(zip_tank, 'e39a8d60a56844d695e9579bce8f0335.xml')\n",
    "c_lab_id_fn = os.path.join(zip_tank, 'class_label_id.csv')\n",
    "\n",
    "im_dir = '../../DigiPath_MLTK_data/RegistrationDevData'\n",
    "im_file = 'e39a8d60a56844d695e9579bce8f0335.tiff'\n",
    "image_file_name = os.path.join(im_dir, im_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priority_ordered_labels(label_id_priority_fname):\n",
    "    \"\"\" ordered_priority_dict = get_priority_ordered_labels(label_id_priority_fname) \n",
    "    read the input .csv file into a priority dictionary struct\n",
    "    \n",
    "    Args:\n",
    "        label_id_priority_fname:    with Header = Label, ID, Priority\n",
    "        \n",
    "    Returns:\n",
    "        ordered_priority_dict:      {priority_number: {'label': label_str, 'ID': str_number}}\n",
    "                                    sorted with largest priority number first\n",
    "    \"\"\"\n",
    "    # create the ordered_priority_dict for return, and a id_priority reverse dict 4 lookups\n",
    "    priority_tuples_list = []\n",
    "    \n",
    "    # read the file\n",
    "    lines = ''\n",
    "    try:        \n",
    "        with open(label_id_priority_fname, 'r') as fh:\n",
    "            lines = fh.readlines()\n",
    "    except:\n",
    "        print('failed opening: ', class_labels_id_file_name)\n",
    "        lines = ''\n",
    "        pass\n",
    "    \n",
    "    # read the .csv lines into the dict   Header = Label, ID, Priority\n",
    "    if len(lines) > 0:\n",
    "        for line in lines:\n",
    "            ln_list = line.strip().split(',')\n",
    "            if len(ln_list) > 1 and ln_list[0] != 'Label':\n",
    "                #                   Fix name clash: .xml \"Id\" vs .csv \"ID\" - Renaming csv-ID as label_ID\n",
    "                # tuple:                    (    priority,     {label: label_name,     ID: ID_number}    )\n",
    "                priority_tuples_list.append((int(ln_list[2]), {'label':ln_list[0],'label_ID':ln_list[1]}))\n",
    "    \n",
    "    return OrderedDict(sorted(priority_tuples_list, reverse=True))\n",
    "    \n",
    "    \n",
    "def get_ordered_priority_label_coords_dict(xml_file_name, label_id_priority_fname):\n",
    "    \"\"\" Usage: \n",
    "    priority_dict = get_ordered_priority_label_coords_dict(xml_file_name, label_id_priority_fname)\n",
    "    parse an xml file for key fields needed for annotation selection of images\n",
    "    \n",
    "    Args:\n",
    "        xml_file_name:              QuPath Annotation convention xml file\n",
    "        label_id_priority_fname:    with columns Label, Id, Priority\n",
    "        \n",
    "    Returns:\n",
    "        priority_dict:              python dict of dicts - with priority numbers as ordered keys,\n",
    "                                        values are python dicts with:\n",
    "                                            label:  Text\n",
    "                                            Text:   label\n",
    "                                            coords: vertices as numpy (n x 2) array [[x, y], [x, y],...]\n",
    "                                            ID:     region Id number - depreciated - defined by label\n",
    "                                            \n",
    "    \"\"\"\n",
    "    # define which region keys to include\n",
    "    REGION_KEYS =  {'Id': 'int', 'Text': 'str', 'Zoom': 'float', 'Analyze': 'bool'}\n",
    "    INT_BOOL_DICT = {1: True, 0:False}\n",
    "    \n",
    "    \n",
    "    # module call:          get the {priority: {label: l, ID: n}\n",
    "    ordered_priority_dict = get_priority_ordered_labels(label_id_priority_fname)\n",
    "    \n",
    "    # read the file into text\n",
    "    with open(xml_file_name, 'r') as fh:\n",
    "        lines = fh.readlines()\n",
    "    \n",
    "    if len(lines) == 0 or ordered_priority_dict is None:\n",
    "        print('\\n\\n\\t\\t\\tThrow_A_Pythonic_Conniption_Fit')\n",
    "        print('\\t\\t\\tFail to read: ',xml_file_name, '\\n\\n')\n",
    "        return ordered_priority_dict\n",
    "\n",
    "    # create the reverse dict  { label:    priority}\n",
    "    label_ID_Priority_dict = {v['label']: k for k, v in ordered_priority_dict.items()}\n",
    "\n",
    "    # initialize region-vertex loop region-coords loop cycle variables\n",
    "    reg_on = False\n",
    "    v_on = False\n",
    "    vertex_list = []\n",
    "    region_dict = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        # region-vertex loop: skip to bottom of loop first, work back up as conditions found\n",
    "        #       finds \"Region\", fills in keys, moves up-loop, \n",
    "        #       finds \"Vertex\" collects all \"Vertex\" tags,\n",
    "        #       takes this first if ... when end of Vertices is found\n",
    "        #       fills \"priority\" defined .csv (reverse dict label_ID_Priority_dict)\n",
    "        if reg_on == True and v_on == True and line.strip() == '</Vertices>':\n",
    "            \n",
    "            # end of region - add region_dict to ordered_priority_dict if coords found\n",
    "            if'Text' in region_dict and len(vertex_list) > 1:\n",
    "                # priority - .csv reverse dict {label: priority} with label==\"Text\" found in xml\n",
    "                priority = label_ID_Priority_dict[region_dict['Text']]\n",
    "                for k in REGION_KEYS.keys():\n",
    "                    if k in region_dict:\n",
    "                        ordered_priority_dict[priority][k] = region_dict[k]\n",
    "                ordered_priority_dict[priority]['vertices'] = np.array(vertex_list)\n",
    "                \n",
    "            else:\n",
    "                #                                                       Throw Warning | Error Here?\n",
    "                print('\\n\\n\\t\\t\\tThrow_A_Pythonic_Conniption_Fit')\n",
    "                print('\\nlen(vertex_list)', len(vertex_list), '\\nregion_dict\\n', region_dict, '\\n\\n')\n",
    "\n",
    "            # restart region-vertex loop: reset all region-coords loop cycle variables\n",
    "            reg_on = False\n",
    "            v_on = False\n",
    "            vertex_list = []\n",
    "            region_dict = {}\n",
    "\n",
    "        elif reg_on == True and v_on == True and '<Vertex' in line.strip()[0:7]:\n",
    "            # add every vertex's coords to the list of coords\n",
    "            \n",
    "            # remove the xml markup and split on empty space, find & insert the X=..., Y=... elements\n",
    "            vertex_line_list = line.strip().strip('<').strip('>').strip('/').split() # .split(' ')\n",
    "            xy_dict = {}\n",
    "            # find\n",
    "            for v in vertex_line_list:\n",
    "                if v[0] == 'X':\n",
    "                    kv_pair = v.split('=')\n",
    "                    xy_dict['X'] = float(kv_pair[1].strip('\"'))\n",
    "\n",
    "                elif v[0] == 'Y':\n",
    "                    kv_pair = v.split('=')\n",
    "                    xy_dict['Y'] = float(kv_pair[1].strip('\"'))\n",
    "\n",
    "            # insert in vertex list\n",
    "            if 'X' in xy_dict and 'Y' in xy_dict:\n",
    "                vertex_list.append([xy_dict['X'], xy_dict['Y']])\n",
    "\n",
    "        if reg_on == True and '<Vertices' in line:\n",
    "            # set to begin parsing Vertex lines\n",
    "            v_on = True\n",
    "\n",
    "        if reg_on == False and '<Region ' in line.strip()[0:8]:\n",
    "            #                       begin parsing the new region\n",
    "            reg_on = True\n",
    "            v_on = False        #   (with paranoia)\n",
    "            region_dict = {}\n",
    "            \n",
    "            # parse this line ( <Region ) to get find key-value pairs named in REGION_KEYS\n",
    "            region_list = line.strip().split()\n",
    "            for reg_item in region_list:\n",
    "                if '=' in reg_item:\n",
    "                    # split into a key-value pair\n",
    "                    item_list = reg_item.strip().split('=')\n",
    "                    if len(item_list) == 2:\n",
    "                        for k in REGION_KEYS:\n",
    "                            # insert key-value pair if key is defined above in REGION_KEYS\n",
    "                            if k in item_list[0][0:len(k)]:\n",
    "                                if REGION_KEYS[k] == 'int':\n",
    "                                    region_dict[k] = int(item_list[1].strip('\"'))\n",
    "                                elif REGION_KEYS[k] == 'float':\n",
    "                                    region_dict[k] = float(item_list[1].strip('\"'))\n",
    "                                elif REGION_KEYS[k] == 'bool':\n",
    "                                    region_dict[k] = INT_BOOL_DICT[int(item_list[1].strip('\"'))]\n",
    "                                else:\n",
    "                                    region_dict[k] = item_list[1].strip('\"')\n",
    "    \n",
    "    return ordered_priority_dict\n",
    "\n",
    "#   get_select_bounds_from_mask\n",
    "def get_select_bounds_from_mask(mask_mat, xy, scale_factor):\n",
    "    \"\"\" Usage: start_stop_dict = get_select_bounds_from_mask(mask_mat, xy='x')\n",
    "    find the first and last unmasked row (y) or col (x) in the mask image input mask_mat\n",
    "    \n",
    "    Args:\n",
    "        mask_mat:           2d numpy binary array\n",
    "        xy:                 character x for x axis or y for y axis\n",
    "        \n",
    "    Returns:\n",
    "        start_stop_dict:    {xy+'_start': _start_, xy+'_end': _stop_}\n",
    "        \n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    _start_ = None\n",
    "    _stop_ = None\n",
    "    \n",
    "    # translate input variables\n",
    "    if xy == 'x':\n",
    "        axis = 1\n",
    "        \n",
    "    elif xy == 'y':\n",
    "        axis = 0\n",
    "        \n",
    "    # sum of axis: sum_of_rows is x, axis=1,\n",
    "    sum_of_axis = mask_mat.sum(axis=axis)\n",
    "    current_greater_than = 0\n",
    "    for k in range(sum_of_axis.size):\n",
    "        if sum_of_axis[k] > 0:\n",
    "            current_greater_than = k\n",
    "            if _start_ is None:\n",
    "                _start_ = k\n",
    "    \n",
    "    # set the last row if a first row one more were found to contain ones\n",
    "    if not _start_ is None and current_greater_than > _start_:\n",
    "        _stop_ = current_greater_than\n",
    "    \n",
    "    # cover the all the way to the include all cases\n",
    "    if _start_ is None:\n",
    "        _start_ = 0\n",
    "        \n",
    "    if _stop_ is None:\n",
    "        _stop_ = sum_of_axis.shape[0] #k\n",
    "\n",
    "    return _start_ * scale_factor, _stop_ * scale_factor\n",
    "\n",
    "def get_region_mask(region_coords, thumbnail_divisor, thumbnail_size): # image_dimensions):\n",
    "    \"\"\" mask_im, img = get_region_mask(region_coords, thumbnail_divisor,image_dimensions) \n",
    "    fabricate a numpy array image mask for thumbnail size with region coords (vertices)\n",
    "    Args:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # scale the region coords tuple with the thumbnail_divisor as type int\n",
    "    xy_list = (region_coords / thumbnail_divisor).astype(np.int).tolist()\n",
    "    xy_list = [(p[1], p[0]) for p in xy_list ]\n",
    "    \n",
    "    img = Image.fromarray(np.zeros((thumbnail_size[1],thumbnail_size[0])).astype(np.uint8))\n",
    "    \n",
    "    # make it a Pillow Draw and draw the polygon from the list of (x,y) tuples\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.polygon(xy_list, fill=\"white\")\n",
    "    \n",
    "    # create the logical mask for patch selection in the return variable\n",
    "    return np.array(img) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../DigiPath_MLTK_data'\n",
    "output_dir = '../../DigiPath_MLTK_data/annotation_test/results'\n",
    "if os.path.isdir(output_dir) == False:\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "wsi_file = 'RegistrationDevData/e39a8d60a56844d695e9579bce8f0335.tiff'\n",
    "wsi_file = os.path.join(data_dir, wsi_file)\n",
    "csv_file = 'wsi_annotation_sample/class_label_id.csv'\n",
    "csv_file = os.path.join(data_dir, csv_file)\n",
    "xml_file = 'wsi_annotation_sample/e39a8d60a56844d695e9579bce8f0335.xml'\n",
    "xml_file = os.path.join(data_dir, xml_file)\n",
    "\n",
    "run_parameters = {'method': 'annotations_to_dir', \n",
    "                  'output_dir': output_dir,\n",
    "                  'wsi_filename': wsi_file, \n",
    "                  'csv_file_name': csv_file,\n",
    "                  'xml_file_name': xml_file,\n",
    "                  'thumbnail_divisor': 56, \n",
    "                  'patch_stride_fraction': 1.0, \n",
    "                  'image_level': 0,  \n",
    "                  'patch_height': 224, \n",
    "                  'patch_width': 224, \n",
    "                  'threshold': 0, \n",
    "                  'patch_select_method': 'threshold_rgb2lab', \n",
    "                  'rgb2lab_threshold': 80}\n",
    "\n",
    "#                                                            define the return variable\n",
    "labeled_masks_dict = defaultdict(dict)\n",
    "\n",
    "# assign local names\n",
    "wsi_filename = run_parameters['wsi_filename']\n",
    "csv_file_name = run_parameters['csv_file_name']\n",
    "xml_file_name = run_parameters['xml_file_name']\n",
    "patch_select_method = run_parameters['patch_select_method']\n",
    "image_level = run_parameters['image_level']\n",
    "\n",
    "# Stride will not scale unless thumbnail_divisor is made of factors of patch_height & patch_width\n",
    "thumbnail_divisor = run_parameters['thumbnail_divisor']\n",
    "\n",
    "# patch_height = max(1, run_parameters['patch_height'] // thumbnail_divisor)\n",
    "# patch_width = max(1, run_parameters['patch_width'] // thumbnail_divisor)\n",
    "patch_height = run_parameters['patch_height']\n",
    "patch_width = run_parameters['patch_width']\n",
    "\n",
    "if 'patch_stride_fraction' in run_parameters:\n",
    "    patch_stride = run_parameters['patch_stride_fraction']\n",
    "else:\n",
    "    patch_stride = 1.0\n",
    "    \n",
    "#                                                            image dimensions, downsamples\n",
    "os_im_obj = openslide.OpenSlide(wsi_filename)\n",
    "image_dimensions = os_im_obj.dimensions\n",
    "obj_downsample = os_im_obj.level_downsamples[image_level]\n",
    "thumbnail_size = (image_dimensions[0] // thumbnail_divisor, image_dimensions[1] // thumbnail_divisor)\n",
    "small_im = os_im_obj.get_thumbnail(thumbnail_size)\n",
    "# thumbnail_size = small_im.size\n",
    "os_im_obj.close()\n",
    "\n",
    "\n",
    "print('image_dimensions', image_dimensions)\n",
    "print('thumbnail_divisor', thumbnail_divisor)\n",
    "print('thumbnail_size', thumbnail_size)\n",
    "print('small_im.size', small_im.size)\n",
    "print('obj_downsample', obj_downsample)\n",
    "print('image_level', run_parameters['image_level'])\n",
    "print('patch_height', patch_height)\n",
    "print('patch_width', patch_width)\n",
    "\n",
    "higher_priorities_mask = get_sample_selection_mask(small_im, patch_select_method, run_parameters=None)\n",
    "print('\\nhigher_priorities_mask.shape', higher_priorities_mask.shape)\n",
    "# thumbnail_size = higher_priorities_mask.shape\n",
    "\n",
    "priority_dict = get_ordered_priority_label_coords_dict(xml_file_name, csv_file_name)\n",
    "for p, p_dict in priority_dict.items():\n",
    "    \n",
    "    label = p_dict['label']\n",
    "    this_mask = get_region_mask(p_dict['vertices'], thumbnail_divisor, thumbnail_size=small_im.size)\n",
    "    print('this_mask.shape', this_mask.shape)\n",
    "    this_mask = np.logical_and(np.logical_not(higher_priorities_mask), this_mask)\n",
    "\n",
    "    if this_mask.sum() > 0:\n",
    "        higher_priorities_mask = np.logical_or(this_mask, higher_priorities_mask)\n",
    "\n",
    "        #                              May not need this in the return -- \n",
    "        p_dict['mask_im'] = this_mask\n",
    "        \n",
    "        #                               bounds scale to full size image\n",
    "        row_start, row_stop = get_select_bounds_from_mask(this_mask, 'y', thumbnail_divisor)\n",
    "        col_start, col_stop = get_select_bounds_from_mask(this_mask, 'x', thumbnail_divisor)\n",
    "        \n",
    "        #                                                                             Bug Nest\n",
    "        p_dict['row_start'] = row_start\n",
    "        p_dict['row_stop'] = row_stop\n",
    "        p_dict['col_start'] = col_start\n",
    "        p_dict['col_stop'] = col_stop\n",
    "        #                               array step scales to image-level downsample\n",
    "        scale_patch_height = patch_height * obj_downsample\n",
    "        rows_fence_array = get_strided_fence_array(scale_patch_height, patch_stride, row_start, row_stop)\n",
    "        p_dict['rows_fence_array'] = rows_fence_array[:,0]\n",
    "\n",
    "        scale_patch_width = patch_width * obj_downsample\n",
    "        cols_fence_array = get_strided_fence_array(scale_patch_width, patch_stride, col_start, col_stop)\n",
    "        p_dict['cols_fence_array'] = cols_fence_array[:,0]\n",
    "\n",
    "        labeled_masks_dict[p] = p_dict\n",
    "\n",
    "print('\\n\\n')\n",
    "print('image_dimensions', image_dimensions)\n",
    "print('thumbnail_size', thumbnail_size)\n",
    "print('image_level', run_parameters['image_level'])\n",
    "print('patch_height', patch_height)\n",
    "print('patch_width', patch_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumbnail_size = (image_dimensions[0] // thumbnail_divisor, image_dimensions[1] // thumbnail_divisor)\n",
    "t_div_0 = image_dimensions[0] // small_im.size[0]\n",
    "t_div_1 = image_dimensions[1] // small_im.size[1]\n",
    "print('thumbnail_divisor', thumbnail_divisor, t_div_0, t_div_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import gcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd(224,56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_list = ['vertices', 'Id', 'label_ID', 'Text', 'Zoom', 'Analyze', 'mask_im']\n",
    "\n",
    "for p, d in labeled_masks_dict.items():\n",
    "    print('\\nPriority: ', p)\n",
    "    for k, v in d.items():\n",
    "        if not k in skip_list and isinstance(v, np.ndarray):\n",
    "            print(k, type(v), v.shape, v.min(), v.max())\n",
    "        elif isinstance(v, str) and not k in skip_list:\n",
    "            print(k, v)\n",
    "        elif not k in skip_list:\n",
    "            print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d['vertices']\n",
    "print(a[:,1])\n",
    "len(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two: get the labeled row-column arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('image_dimensions-pixels:\\t %i columns,\\t%i rows'%(image_dimensions))\n",
    "print('thumbnail_divisor', thumbnail_divisor)\n",
    "print('thumbnail_size', thumbnail_size)\n",
    "print('small_im.size', small_im.size)\n",
    "print('obj_downsample', obj_downsample)\n",
    "print('image_level', run_parameters['image_level'])\n",
    "print('patch_height', patch_height)\n",
    "print('patch_width', patch_width)\n",
    "\n",
    "d = labeled_masks_dict[7]\n",
    "for p, d in labeled_masks_dict.items():\n",
    "    print('\\nPriority: ', p)\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            if len(v.shape) == 2:\n",
    "                print('%20s'%(k), v.shape, \n",
    "                      'x = (min=%0.2f, max=%0.2f) '%(v[:,0].min(), v[:,0].max()), \n",
    "                      'y = (min=%0.2f, max=%0.2f) '%(v[:,1].min(), v[:,1].max()))\n",
    "            else:\n",
    "                print('%20s'%(k), v.shape, '(min=%0.2f, max=%0.2f) '%(v.min(), v.max()))\n",
    "        else:\n",
    "            print('%20s: %s'%(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Step One: get the priority-labeled-Vertexes dictionary from the input files\n",
    "### show usage of *get_ordered_priority_label_coords_dict(xml_file, label_priority_file)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_name = os.path.join(zip_tank, 'e39a8d60a56844d695e9579bce8f0335.xml')\n",
    "label_id_priority_fname = os.path.join(zip_tank, 'class_label_id.csv')\n",
    "\n",
    "priority_dict = get_ordered_priority_label_coords_dict(xml_file_name, label_id_priority_fname)\n",
    "print('\\npriority_dict\\n')\n",
    "if len(priority_dict) > 0:\n",
    "    for k, v in priority_dict.items():\n",
    "        s = '%i '%(k)\n",
    "        for nm, vl in v.items():\n",
    "            if nm == 'vertices':\n",
    "                s += '\\tvertices: %4i'%(len(vl))\n",
    "            elif nm == 'Id':\n",
    "                s += '%3s: %s'%(nm,vl)\n",
    "            elif nm in ['label', 'Text']:\n",
    "                s += '%6s: %9s'%(nm,vl)\n",
    "            else:\n",
    "                s += '%9s: %s'%(nm,vl)\n",
    "        print(s)\n",
    "else:\n",
    "    print('de Nada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reference: Input files summary\n",
    "****\n",
    "#### priority_dict = get_ordered_priority_label_coords_dict(xml_file_name, label_id_priority_fname): function output print\n",
    "```text\n",
    "priority_dict\n",
    "\n",
    "7               normal\t True \t   4 coords \tlabel_ID 7 \tId 4\n",
    "6                  ink\t True \t 619 coords \tlabel_ID 6 \tId 8\n",
    "5               offset\t True \t   3 coords \tlabel_ID 5 \tId 1\n",
    "4            malignant\t True \t 133 coords \tlabel_ID 4 \tId 3\n",
    "3               Region\t True \t   4 coords \tlabel_ID 3 \tId 2\n",
    "2                lymph\t True \t 152 coords \tlabel_ID 2 \tId 7\n",
    "1                  fat\t True \t   4 coords \tlabel_ID 1 \tId 5\n",
    "0                 null\t True \t 110 coords \tlabel_ID 0 \tId 6\n",
    "```\n",
    "##### input file: class_label_id.csv\n",
    "```\n",
    "Label\t   ID\tPriority\n",
    "null       0     0\n",
    "fat        1     1\n",
    "lymph      2     2\n",
    "Region     3     3\n",
    "malignant  4     4\n",
    "offset     5     5\n",
    "ink        6     6\n",
    "normal     7     7\t\n",
    "```\n",
    "##### input fiile: e39a8d60a56844d695e9579bce8f0335.xml\n",
    "```\n",
    "Id = 1 \tText =     offset \tType = 5\n",
    "Id = 2 \tText =     Region \tType = 3\n",
    "Id = 3 \tText =  malignant \tType = 4\n",
    "Id = 4 \tText =     normal \tType = 7\n",
    "Id = 5 \tText =        fat \tType = 1\n",
    "Id = 6 \tText =       null \tType = 0\n",
    "Id = 7 \tText =      lymph \tType = 2\n",
    "Id = 8 \tText =        ink \tType = 6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
