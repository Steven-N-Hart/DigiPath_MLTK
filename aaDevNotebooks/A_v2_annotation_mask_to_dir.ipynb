{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "from math import gcd\n",
    "from collections import defaultdict, OrderedDict\n",
    "import json\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openslide\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "py_src_code_dir = '../src/python'\n",
    "sys.path.insert(0, py_src_code_dir)\n",
    "from digipath_toolkit import get_sample_selection_mask, get_strided_fence_array\n",
    "from digipath_toolkit import get_patch_location_array_for_image_level\n",
    "\n",
    "data_dir = '../../DigiPath_MLTK_data'\n",
    "zip_tank = '../../DigiPath_MLTK_data/zipTank/wsi_annotation_sample/'\n",
    "xml_name = os.path.join(zip_tank, 'e39a8d60a56844d695e9579bce8f0335.xml')\n",
    "c_lab_id_fn = os.path.join(zip_tank, 'class_label_id.csv')\n",
    "\n",
    "im_dir = '../../DigiPath_MLTK_data/RegistrationDevData'\n",
    "im_file = 'e39a8d60a56844d695e9579bce8f0335.tiff'\n",
    "image_file_name = os.path.join(im_dir, im_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(xml_name)\n",
    "root = tree.getroot()\n",
    "for region in root.iter('class_label_text'):\n",
    "    print(region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(xml_name)\n",
    "root = tree.getroot()\n",
    "for label in root.findall('Regions/Region_Id'):\n",
    "    print(type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(xml_name, 'r') as fh:\n",
    "    lines = fh.read()\n",
    "\n",
    "dom = minidom.parseString(lines)\n",
    "regions = dom.getElementsByTagName('Region')\n",
    "print(type(regions), len(regions))\n",
    "for r in regions:\n",
    "    print(r.getAttribute('Text'), r.getAttribute('Id'), r.getAttribute('Type'), r.getAttribute('GeoShape'), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from xml.dom import minidom\n",
    "\n",
    "xml_obj = minidom.parse(xml_file_name)\n",
    "regions_dom = xml_obj.getElementsByTagName(\"Region\")\n",
    "\n",
    "regions_list = []\n",
    "for reg_dom in regions_dom:\n",
    "    tmp_dict = {}\n",
    "    vertices = reg_dom.getElementsByTagName(\"Vertex\")\n",
    "    tmp_dict['region_Id'] = reg_dom.getAttribute('Id')\n",
    "    tmp_dict['class_label_text'] = reg_dom.getAttribute('Text')\n",
    "    tmp_dict['class_label_Id'] = reg_dom.getAttribute('Type')\n",
    "    tmp_dict['region_geo_shape'] = reg_dom.getAttribute('GeoShape')\n",
    "    tmp_dict['coords'] = np.zeros((len(vertices), 2))\n",
    "    for i, vertex in enumerate(vertices):\n",
    "        tmp_dict['coords'][i][0] = vertex.attributes['X'].value\n",
    "        tmp_dict['coords'][i][1] = vertex.attributes['Y'].value\n",
    "\n",
    "    regions_list.append(tmp_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(minidom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Annotation: labeled patches from .xml, .csv, .svs\n",
    "(and display all for developer sanity check)\n",
    "\n",
    "## Convert xml & csv input to a region_id dict\n",
    "\n",
    "## Create heirarchical mask set from the region_id dict\n",
    "\n",
    "## Write labeled patches from the heirarchical mask set\n",
    "\n",
    "```text\n",
    "Questions:\n",
    "    We should still create a threshold mask as before to omit any blank areas included in an annotation?\n",
    "    Yes.\n",
    " \n",
    "    When an entire label is eclipsed by a higher priority label (Empty) should the function issue a warning?\n",
    "    No.\n",
    " \n",
    "    The TFRecord could now have more than one “class_label” and,\n",
    "    the “label” field that TFRecord owns is still just a sequence number… \n",
    "    thus it may be more difficult to select training/test subsets.\n",
    "    Ergo: should each “class_label” aka “class_label_text” be in a different TFRecord file?\n",
    "    No - one file is fine\n",
    "```\n",
    "\n",
    "## Givin a WSI, an Annotation File and an Annotation Labels priority dictionary file\n",
    "\n",
    "1) Annotation file must follow the QuPath Annotation convention. <br>\n",
    "2) Labels dictionary required to assign priority. <br>\n",
    "****\n",
    "```python\n",
    "# read the Annotation File and the labels priority dict into a regions dictionary:\n",
    "# read the regions dictionary into a labels dict\n",
    "#    for each label\n",
    "#        get the mask,\n",
    "#        add the patches to the tfrecord or write the files,\n",
    "\n",
    "```\n",
    "\n",
    "### Issue: thumbnail_divisor too large makes patch test smaller than one pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from math import gcd\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from xml.dom import minidom\n",
    "\n",
    "import openslide\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\"\"\"\n",
    "\n",
    "# def get_nearest_thumbnail_divisor(patch_dim, thumbnail_divisor):\n",
    "#     \"\"\" nearest_thumbnail_divisor = get_nearest_thumbnail_divisor(patch_dim, thumbnail_divisor)\n",
    "    \n",
    "#     Args:\n",
    "#         patch_dim:                  integer size of patch (assuming square patch)\n",
    "#         thumbnail_divisor:          integer thumbnail_divisor\n",
    "        \n",
    "#     Returns:\n",
    "#         nearest_thumbnail_divisor:  largest, nearest in list of divisors of patch_dim\n",
    "#     \"\"\"\n",
    "#     patch_size = int(patch_dim)\n",
    "#     nearest_thumbnail_divisor = thumbnail_divisor\n",
    "#     even_divisors_list = get_even_thumbnail_divisors(patch_dim)\n",
    "    \n",
    "#     min_diff = patch_size\n",
    "#     nearest_div = 1\n",
    "#     for t in even_divisors_list:\n",
    "#         d = t - thumbnail_divisor\n",
    "#         da = np.abs(d)\n",
    "#         if min_diff >= da:\n",
    "#             min_diff = da\n",
    "#             nearest_thumbnail_divisor = t\n",
    "\n",
    "#     return nearest_thumbnail_divisor\n",
    "\n",
    "# def get_even_thumbnail_divisors(patch_dim):\n",
    "#     \"\"\" Usage: even_divisors_list = get_even_thumbnail_divisors(patch_size)\n",
    "#     find thumbnail divisors that won't distort the patch size | stride in the thumbnail image\n",
    "    \n",
    "#     Args:\n",
    "#         patch_dim:              integer size of patch (assuming square patch)\n",
    "        \n",
    "#     Returns:\n",
    "#         even_divisors_list:     unique factors of patch_dim\n",
    "#     \"\"\"\n",
    "#     patch_size = int(patch_dim)\n",
    "#     thum_div_set = {1}\n",
    "#     for trial_div in range(2, 1 + patch_size // 2):\n",
    "#         thum_div_set.add(gcd(patch_size, trial_div))\n",
    "        \n",
    "#     return sorted(list(thum_div_set))\n",
    "\n",
    "def get_labels_dict(class_labels_id_file_name):\n",
    "    \"\"\" labels_dict = get_labels_dict(class_labels_id) \n",
    "    Args:\n",
    "        class_labels_id_file_name:  .csv file with columns [Label, ID, Priority]\n",
    "    Returns:\n",
    "        labels_dict:                python dict of dicts:\n",
    "                                        {label_id_(n): {ID: x, Priority: y}, ...}\n",
    "    \"\"\"\n",
    "    # allocate dict of dicts\n",
    "    labels_dict = defaultdict(dict)\n",
    "    \n",
    "    # read the file\n",
    "    lines = ''\n",
    "    try:        \n",
    "        with open(class_labels_id_file_name, 'r') as fh:\n",
    "            lines = fh.readlines()\n",
    "    except:\n",
    "        print('failed opening: ', class_labels_id_file_name)\n",
    "        lines = ''\n",
    "        pass\n",
    "    \n",
    "    # read the lines into the dict\n",
    "    if len(lines) > 0:\n",
    "        for line in lines:\n",
    "            line_list = line.strip().split(',')\n",
    "            if len(line_list) > 1 and line_list[0] != 'Label':\n",
    "                labels_dict[line_list[0]] = {'ID': line_list[1], 'Priority': line_list[1]}\n",
    "                \n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def get_xml_list_of_dicts(xml_file_name):\n",
    "    \"\"\" regions_list = get_xml_list_of_dicts(xml_file_name) \n",
    "    Args:\n",
    "        xml_file_name:  required TagName\n",
    "                            Vertex\n",
    "                        required Attributes\n",
    "                            Id\n",
    "                            Text\n",
    "                            Type\n",
    "                            GeoShape\n",
    "    Returns:\n",
    "        regions_list:   list of dicts with keys:\n",
    "                            region_Id\n",
    "                            class_label_text\n",
    "                            class_label_Id\n",
    "                            region_geo_shape\n",
    "                            coords\n",
    "    \"\"\"\n",
    "    \n",
    "    xml_obj = minidom.parse(xml_file_name)\n",
    "    regions_dom = xml_obj.getElementsByTagName(\"Region\")\n",
    "\n",
    "    regions_list = []\n",
    "    for reg_dom in regions_dom:\n",
    "        tmp_dict = {}\n",
    "        vertices = reg_dom.getElementsByTagName(\"Vertex\")\n",
    "        tmp_dict['region_Id'] = reg_dom.getAttribute('Id')\n",
    "        tmp_dict['class_label_text'] = reg_dom.getAttribute('Text')\n",
    "        tmp_dict['class_label_Id'] = reg_dom.getAttribute('Type')\n",
    "        tmp_dict['coords'] = np.zeros((len(vertices), 2))\n",
    "        for i, vertex in enumerate(vertices):\n",
    "            tmp_dict['coords'][i][0] = vertex.attributes['X'].value\n",
    "            tmp_dict['coords'][i][1] = vertex.attributes['Y'].value\n",
    "            \n",
    "        regions_list.append(tmp_dict)\n",
    "        \n",
    "    return regions_list\n",
    "\n",
    "\n",
    "def get_region_Id_dict(xml_file_name, class_labels_id_file_name):\n",
    "    \"\"\" region_id_dict = get_region_Id_dict(xml_file_name, class_labels_id_file_name) \n",
    "    \"\"\"\n",
    "    # read the xml file into a list of dicts\n",
    "    regions_list = get_xml_list_of_dicts(xml_file_name)\n",
    "    \n",
    "    # read the csv file into a dict of dicts Label: {ID: x, Priority: y}\n",
    "    label_dict = get_labels_dict(class_labels_id_file_name)\n",
    "    \n",
    "    # initialize the output dictionary\n",
    "    region_id_dict = defaultdict(dict)\n",
    "    \n",
    "    # enter each region into the output dict\n",
    "    for region_dict in regions_list:\n",
    "        # extract and cast the region Priority from the csv file\n",
    "        region_priority = int(label_dict[region_dict['class_label_text']]['Priority'])\n",
    "        \n",
    "        # construct the rest of the region dict from the xml file\n",
    "        ridic = {'class_label_text': region_dict['class_label_text'], \n",
    "                 'class_label_Id': region_dict['class_label_Id'], \n",
    "                 'Priority': region_priority, \n",
    "                 'coords': region_dict['coords']}\n",
    "        \n",
    "        region_id_dict[int(region_dict['region_Id'])] = ridic\n",
    "        \n",
    "    return region_id_dict\n",
    "\n",
    "    \n",
    "def regions_dict_to_priority_dict(regions_dict):\n",
    "    \"\"\" priority_dict, priority_list =   regions_dict_to_priority_dict(regions_dict) \n",
    "                        convert a regions_id_dict to a labels dict with data preserved\n",
    "    \n",
    "    Args:\n",
    "        regions_dict:   such as returned by get_region_Id_dict(xml_file, csv_labels)\n",
    "        \n",
    "    Returns:\n",
    "        priority_dict:    same data with labels as keys to list of regions dicts\n",
    "        priority_list:    ordered highest to lowest (largest)\n",
    "    \"\"\"\n",
    "    priority_list = []\n",
    "    priority_dict = defaultdict(list)\n",
    "    for k_reg_id, reg_dict in regions_dict.items():\n",
    "        reg_dict['region_Id'] = k_reg_id\n",
    "        priority_dict[reg_dict['Priority']].append(reg_dict)\n",
    "        priority_list.append(reg_dict['Priority'])\n",
    "        \n",
    "    priority_list = sorted(priority_list, reverse=True)\n",
    "        \n",
    "    return priority_dict, priority_list\n",
    "\n",
    "\n",
    "def get_region_mask(region_coords, thumbnail_divisor, thumbnail_size): # image_dimensions):\n",
    "    \"\"\" mask_im, img = get_region_mask(region_coords, thumbnail_divisor,image_dimensions) \n",
    "    \"\"\"\n",
    "    # scale the region coords tuple with the thumbnail_divisor as type int\n",
    "    xy_list = (region_coords / thumbnail_divisor).astype(np.int).tolist()\n",
    "    xy_list = [(p[0], p[1]) for p in xy_list ]\n",
    "    \n",
    "    img = Image.fromarray(np.zeros(thumbnail_size).astype(np.uint8))\n",
    "    \n",
    "    # make it a Pillow Draw and draw the polygon from the list of (x,y) tuples\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.polygon(xy_list, fill=\"white\")\n",
    "    \n",
    "    # create the logical mask for patch selection in the return variable\n",
    "    return np.array(img) > 0\n",
    "\n",
    "\n",
    "def get_select_bounds_from_mask(mask_mat, xy='x'):\n",
    "    \"\"\" Usage: start_stop_dict = get_select_bounds_from_mask(mask_mat, xy='x')\n",
    "    find the first and last unmasked row (y) or col (x) in the mask image input mask_mat\n",
    "    \n",
    "    Args:\n",
    "        mask_mat:           2d numpy binary array\n",
    "        xy:                 character x for x axis or y for y axis\n",
    "        \n",
    "    Returns:\n",
    "        start_stop_dict:    {xy+'_start': _start_, xy+'_end': _stop_}\n",
    "        \n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    _start_ = None\n",
    "    _stop_ = None\n",
    "    \n",
    "    # translate input variables\n",
    "    if xy == 'x':\n",
    "        axis = 1\n",
    "        \n",
    "    elif xy == 'y':\n",
    "        axis = 0\n",
    "        \n",
    "    # sum of axis: sum_of_rows is x, axis=1,\n",
    "    sum_of_axis = mask_mat.sum(axis=axis)\n",
    "    current_greater_than = 0\n",
    "    for k in range(sum_of_axis.size):\n",
    "        if sum_of_axis[k] > 0:\n",
    "            current_greater_than = k\n",
    "            if _start_ is None:\n",
    "                _start_ = k\n",
    "    \n",
    "    # set the last row if a first row one more were found to contain ones\n",
    "    if not _start_ is None and current_greater_than > _start_:\n",
    "        _stop_ = current_greater_than\n",
    "    \n",
    "    # cover the all the way to the include all cases\n",
    "    if _start_ is None:\n",
    "        _start_ = 0\n",
    "        \n",
    "    if _stop_ is None:\n",
    "        _stop_ = k\n",
    "        \n",
    "    # name the return values with the expected x, y input\n",
    "    start_stop_dict = {xy+'_start': _start_, xy+'_end': _stop_}\n",
    "    \n",
    "    return start_stop_dict\n",
    "\n",
    "def get_labeled_mask_dict(run_parameters):\n",
    "    \"\"\" Usage: labeled_masks_dict = get_labeled_masks_dict(run_parameters)\n",
    "    Prioritized dictionary for each region defined in the input xml and csv\n",
    "    \n",
    "    {label: patch_selection_mask, ... } \n",
    "    \n",
    "    Args:\n",
    "        run_parameters:             with keys:\n",
    "                                        csv_file_name\n",
    "                                        xml_file_name\n",
    "                                        thumbnail_divisor\n",
    "                                        wsi_filename\n",
    "                                    \n",
    "    Returns:\n",
    "        heirarchical_mask_dict:     {label_1: mask_image, ...}\n",
    "        \n",
    "    \"\"\"  \n",
    "    # define the return variable\n",
    "    labeled_masks_dict = defaultdict(dict)\n",
    "    \n",
    "    # assign local names\n",
    "    wsi_filename = run_parameters['wsi_filename']\n",
    "    csv_file_name = run_parameters['csv_file_name']\n",
    "    xml_file_name = run_parameters['xml_file_name']\n",
    "    patch_select_method = run_parameters['patch_select_method']\n",
    "    \n",
    "    # Stride will not scale unless thumbnail_divisor is made of factors of patch_height & patch_width\n",
    "    thumbnail_divisor = run_parameters['thumbnail_divisor']\n",
    "    \n",
    "    patch_dim = max(run_parameters['patch_height'], run_parameters['patch_width'])\n",
    "    #thumbnail_divisor = get_nearest_thumbnail_divisor(patch_dim, thumbnail_divisor)\n",
    "    #print('Using thumbnail_divisor =', thumbnail_divisor)\n",
    "    \n",
    "    \n",
    "    patch_height = max(1, run_parameters['patch_height'] // thumbnail_divisor)\n",
    "    patch_width = max(1, run_parameters['patch_width'] // thumbnail_divisor)\n",
    "    \n",
    "    if 'patch_stride_fraction' in run_parameters:\n",
    "        patch_stride = run_parameters['patch_stride_fraction']\n",
    "    else:\n",
    "        patch_stride = 1.0\n",
    "    \n",
    "    # get the priority dict and list of what is in it\n",
    "    regions_dict = get_region_Id_dict(xml_file_name, csv_file_name)\n",
    "    priority_dict, priority_list = regions_dict_to_priority_dict(regions_dict)\n",
    "    \n",
    "    #       initialize the priority mask\n",
    "    os_im_obj = openslide.OpenSlide(wsi_filename)\n",
    "    image_dimensions = os_im_obj.dimensions\n",
    "    thumbnail_size = (image_dimensions[0] // thumbnail_divisor, image_dimensions[1] // thumbnail_divisor)\n",
    "    small_im = os_im_obj.get_thumbnail(thumbnail_size)\n",
    "    os_im_obj.close()\n",
    "\n",
    "    higher_priorities_mask = get_sample_selection_mask(small_im, patch_select_method, run_parameters=None)\n",
    "    thumbnail_size = higher_priorities_mask.shape\n",
    "    \n",
    "    # iterate the priority dict into the heirarchical mask set \n",
    "    # -- subtracting all higher priority masks from the new lower ones\n",
    "    for p in priority_list:\n",
    "        if len(priority_dict[p]) > 1:\n",
    "            print('\\n\\n\\t\\tDire Warning: In Function get_labeled_mask_dict\\n\\n')\n",
    "            print('\\n\\n\\t\\tDire Warning: More than one label with same Priority\\n\\n')\n",
    "            print('\\n\\n\\t\\tDire Warning: Only using first label in each Priority Level\\n\\n')\n",
    "        p_dict = priority_dict[p]    \n",
    "        #p_dict = priority_dict[p][0]\n",
    "        label = p_dict['class_label_text']\n",
    "        this_mask = get_region_mask(p_dict['coords'], thumbnail_divisor, thumbnail_size) # image_dimensions)\n",
    "        this_mask = np.logical_and(np.logical_not(higher_priorities_mask), this_mask)\n",
    "        \n",
    "        if this_mask.sum() > 0:\n",
    "            higher_priorities_mask = np.logical_or(this_mask, higher_priorities_mask)\n",
    "            \n",
    "            #                              May not need this in the return -- \n",
    "            p_dict['mask_im'] = this_mask\n",
    "            \n",
    "            start_stop_rows = get_select_bounds_from_mask(this_mask, xy='y')\n",
    "            row_start, row_end = start_stop_rows['y_start'], start_stop_rows['y_end']\n",
    "            rows_fence_array = get_strided_fence_array(patch_height, patch_stride, row_start, row_end)\n",
    "            p_dict['rows_fence_array'] = rows_fence_array[:,0] * thumbnail_divisor\n",
    "\n",
    "            start_stop_cols = get_select_bounds_from_mask(this_mask, xy='x')\n",
    "            col_start, col_end = start_stop_cols['x_start'], start_stop_cols['x_end']\n",
    "            cols_fence_array = get_strided_fence_array(patch_width, patch_stride, col_start, col_end)\n",
    "            p_dict['cols_fence_array'] = cols_fence_array[:,0] * thumbnail_divisor\n",
    "            \n",
    "            labeled_masks_dict[p] = p_dict\n",
    "            \n",
    "    return labeled_masks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priority_dict(xml_file_name, class_labels_id_file_name):\n",
    "    \"\"\" priority_dict = get_region_Id_dict(xml_file_name, class_labels_id_file_name) \n",
    "    \"\"\"\n",
    "    # read the xml file into a list of dicts\n",
    "    regions_list = get_xml_list_of_dicts(xml_file_name)\n",
    "    \n",
    "    # read the csv file into a dict of dicts Label: {ID: x, Priority: y}\n",
    "    label_dict = get_labels_dict(class_labels_id_file_name)\n",
    "    \n",
    "    # initialize the output dictionary\n",
    "    region_id_dict = defaultdict(dict)\n",
    "    \n",
    "    # enter each region into the output dict\n",
    "    for region_dict in regions_list:\n",
    "        # extract and cast the region Priority from the csv file\n",
    "        region_priority = int(label_dict[region_dict['class_label_text']]['Priority'])\n",
    "        \n",
    "        # construct the rest of the region dict from the xml file\n",
    "        ridic = {'class_label_text': region_dict['class_label_text'], \n",
    "                 'class_label_Id': region_dict['class_label_Id'], \n",
    "                 'Priority': region_priority, \n",
    "                 'coords': region_dict['coords']}\n",
    "        \n",
    "        region_id_dict[int(region_dict['region_Id'])] = ridic\n",
    "        \n",
    "    return region_id_dict    \n",
    "    \n",
    "p_dict = get_priority_dict(xml_file_name=xml_name, class_labels_id_file_name=c_lab_id_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(c_lab_id_fn).fillna('null')\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Priority = labels_df.loc[labels_df['ID'] == 1]['Priority']\n",
    "Label = labels_df.loc[labels_df['ID'] == 1]['Label']\n",
    "\n",
    "print(Priority, Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels_df.loc[labels_df['ID'] == 1])\n",
    "labels_df.loc[labels_df['ID'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(c_lab_id_fn, index_col=0)\n",
    "od_list = []\n",
    "for r, row in labels_df.iterrows():\n",
    "    if isinstance(r, float) and np.isnan(r) == True:\n",
    "        print('%i, %i, %s'%(row['ID'], row['Priority'], 'null'))\n",
    "        od_list.append((row['Priority'], 'null'))\n",
    "    else:\n",
    "        print('%i, %i, %s'%(row['ID'], row['Priority'], r))\n",
    "        od_list.append((row['Priority'], r))\n",
    "\n",
    "# od_dakine = OrderedDict(sorted(od_list))\n",
    "# for k, v in od_dakine.items():\n",
    "#     print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yo lo necissito:\n",
    "```python\n",
    "\n",
    "priority_dict = OrderedDict((priority_integer_max, {'class_label_text': clt, 'coords': np2d_array}),\n",
    "                            (priority_integer_max-1, {'class_label_text': clt, 'coords': np2d_array}), ...)\n",
    "```\n",
    "\n",
    "## y no mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_dict_list = []\n",
    "\n",
    "print('with file: %s'%(xml_name))\n",
    "labels_df = pd.read_csv(c_lab_id_fn, index_col=0).\n",
    "\n",
    "xml_obj = minidom.parse(xml_name)\n",
    "regions_dom = xml_obj.getElementsByTagName(\"Region\")\n",
    "\n",
    "regions_list = []\n",
    "for reg_dom in regions_dom:\n",
    "    tmp_dict = {}\n",
    "    vertices = reg_dom.getElementsByTagName(\"Vertex\")\n",
    "    tmp_dict['region_Id'] = reg_dom.getAttribute('Id')\n",
    "    tmp_dict['class_label_text'] = reg_dom.getAttribute('Text')\n",
    "    tmp_dict['class_label_Id'] = reg_dom.getAttribute('Type')\n",
    "    tmp_dict['coords'] = np.zeros((len(vertices), 2))\n",
    "    for i, vertex in enumerate(vertices):\n",
    "        tmp_dict['coords'][i][0] = vertex.attributes['X'].value\n",
    "        tmp_dict['coords'][i][1] = vertex.attributes['Y'].value\n",
    "\n",
    "    regions_list.append(tmp_dict)\n",
    "    priority = \n",
    "    priority_dict_list.append((reg_dom.getAttribute('Text'), {'class_label_text': reg_dom.getAttribute('Text')}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in get_labels_dict(class_labels_id_file_name=c_lab_id_fn).items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_dict in get_xml_list_of_dicts(xml_file_name=xml_name):\n",
    "    for k, v in r_dict.items():\n",
    "        print(k, v )\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid_dic = get_region_Id_dict(xml_file_name=xml_name, class_labels_id_file_name=c_lab_id_fn)\n",
    "# priority_dict, priority_list = regions_dict_to_labels_dict(rid_dic)\n",
    "priority_dict, priority_list =   regions_dict_to_priority_dict(rid_dic)\n",
    "for k in priority_list:\n",
    "    print('priority level:', k, 'number of items', len(priority_dict[k]), 'type', type(priority_dict[k][0]))\n",
    "    for lbl, v in priority_dict[k][0].items():\n",
    "        if isinstance(v, np.ndarray):\n",
    "            print('\\t', lbl, v.shape)\n",
    "        else:\n",
    "            print('\\t', lbl, v)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../DigiPath_MLTK_data'\n",
    "output_dir = '../../DigiPath_MLTK_data/annotation_test/results'\n",
    "if os.path.isdir(output_dir) == False:\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "wsi_file = 'RegistrationDevData/e39a8d60a56844d695e9579bce8f0335.tiff'\n",
    "wsi_file = os.path.join(data_dir, wsi_file)\n",
    "csv_file = 'wsi_annotation_sample/class_label_id.csv'\n",
    "csv_file = os.path.join(data_dir, csv_file)\n",
    "xml_file = 'wsi_annotation_sample/e39a8d60a56844d695e9579bce8f0335.xml'\n",
    "xml_file = os.path.join(data_dir, xml_file)\n",
    "\n",
    "run_parameters = {'method': 'annotations_to_dir', \n",
    "                  'output_dir': output_dir,\n",
    "                  'wsi_filename': wsi_file, \n",
    "                  'csv_file_name': csv_file,\n",
    "                  'xml_file_name': xml_file,\n",
    "                  'thumbnail_divisor': 100, \n",
    "                  'patch_stride_fraction': 1.0, \n",
    "                  'image_level': 0,  \n",
    "                  'patch_height': 224, \n",
    "                  'patch_width': 224, \n",
    "                  'threshold': 0, \n",
    "                  'patch_select_method': 'threshold_rgb2lab', \n",
    "                  'rgb2lab_threshold': 80}\n",
    "\n",
    "t0 = time.time()\n",
    "label_mask_dict = get_labeled_mask_dict(run_parameters)\n",
    "tt = time.time() - t0\n",
    "print('run_time %0.3f initial thumbnail_divisor: %0.6f\\n'%(tt, run_parameters['thumbnail_divisor']))\n",
    "for label, lbl_dict in label_mask_dict.items():\n",
    "    print('level', label, 'label', lbl_dict['class_label_text'], '\\t', type(lbl_dict), len(lbl_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "normal <class 'numpy.ndarray'>\n",
    "ink <class 'numpy.ndarray'>\n",
    "offset <class 'numpy.ndarray'>\n",
    "malignant <class 'numpy.ndarray'>\n",
    "Region <class 'numpy.ndarray'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in lbl_dict.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(lbl_dict))\n",
    "rows_fence_arr = lbl_dict['rows_fence_array']\n",
    "print(type(rows_fence_arr), rows_fence_arr.shape)\n",
    "for idx in range(rows_fence_arr.shape[0] - 1):\n",
    "    print('row: %6i\\tstride: %i'%(rows_fence_arr[idx], rows_fence_arr[idx+1] - rows_fence_arr[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review-test notebook implemented functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Test function: get_labeled_masks(run_parameters)\n",
    "        \n",
    "        Expected - one labeled mask per priority level unless mask is blank\n",
    "        \n",
    "\"\"\"\n",
    "t0 = time.time()\n",
    "# labeled_masks_dict = get_labeled_masks(run_parameters)\n",
    "labeled_masks_dict = get_labeled_mask_dict(run_parameters)\n",
    "\n",
    "for merge_label, merged_lbl_msk in labeled_masks_dict.items():\n",
    "    if merged_lbl_msk['mask_im'].sum() == 0:\n",
    "        print(merge_label, 'Is Empty Mask')\n",
    "    else:\n",
    "        m_lbl_im = Image.fromarray((merged_lbl_msk['mask_im'].astype(np.uint8) * 255))\n",
    "        print('mask for %s'%(merge_label))\n",
    "        display(m_lbl_im)\n",
    "    \n",
    "print('total run time: %0.3f'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Test - demo            regions_dict = get_region_Id_dict(xml_name, c_lab_id_fn)\n",
    "\n",
    "        Test - demo            priority_dict, priority_list= regions_dict_to_priority_dict(regions_dict)\n",
    "\n",
    "Note that in this test set (xml, csv) there is only one class label per priority level\n",
    "\"\"\"\n",
    "regions_dict = get_region_Id_dict(xml_name, c_lab_id_fn)\n",
    "priority_dict, priority_list = regions_dict_to_priority_dict(regions_dict)\n",
    "\n",
    "for p in priority_list:\n",
    "    lbl_dict_list = priority_dict[p]\n",
    "    print('\\nPriority:', p, '\\t(%i dictionaries)'%(len(lbl_dict_list)))\n",
    "    for lbl_dict in lbl_dict_list:\n",
    "        for k, v in lbl_dict.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                print('%20s:'%(k), v[0,:])\n",
    "                for v_ix in range(len(v) - 1):\n",
    "                    print('%20s '%(' '), v[v_ix+1,:])\n",
    "            else:\n",
    "                print('%20s:'%(k), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumbnail divisor is remainder madness unless it is a divisor of pathch size \n",
    "patch_size = 224\n",
    "thumbnail_divisor_test = 5\n",
    "\n",
    "thm_div_list = get_even_thumbnail_divisors(patch_dim=patch_size)\n",
    "print('get_even_thumbnail_divisors returns list:\\n')\n",
    "for t in thm_div_list:\n",
    "    d = t - thumbnail_divisor_test\n",
    "    da = np.abs(d)\n",
    "    print(t, da)\n",
    "\n",
    "print('\\n\\nfunction returns', get_nearest_thumbnail_divisor(patch_size, thumbnail_divisor_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        n_pixels_per_stride = patch_size * patch_stride\n",
    "        patch_stride = n_pixels_per_stride / patch_size\n",
    "\"\"\"\n",
    "_MIN_STRIDE_PIXELS = 3\n",
    "_patch_stride = 0.1\n",
    "_patch_width = _patch_height = 224\n",
    "\n",
    "#       assure minimum stride s.t. arrays advance by at least MIN_STRIDE_PIXELS\n",
    "_patch_stride = max(_patch_stride, (_MIN_STRIDE_PIXELS / min(_patch_width, _patch_height) ) )\n",
    "print(_patch_stride, _patch_stride * min(_patch_width, _patch_height) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "im_rgbA = Image.fromarray((np.random.random((200,200,4))* 255).astype(np.uint8) )\n",
    "print('image (with alpha channel) RGB')\n",
    "display(im_rgbA)\n",
    "\n",
    "im_rgb = im_rgbA.convert('RGB')\n",
    "print('image (alpha channel removed) RGB')\n",
    "display(im_rgb)\n",
    "\n",
    "im_gray_from_rgb = im_rgb.convert('L')\n",
    "print('image gray from RGB')\n",
    "display(im_gray_from_rgb)\n",
    "\n",
    "im_gray = Image.fromarray((np.random.random((200,200))* 255).astype(np.uint8) )\n",
    "print('image grayscale from 2D array')\n",
    "display(im_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
