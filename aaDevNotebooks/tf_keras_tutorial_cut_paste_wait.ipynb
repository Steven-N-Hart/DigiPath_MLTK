{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\"\"\" \n",
    "        else keras crash (tf.keras.utils.get_file)\n",
    "\"\"\"\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook:\n",
    "[tf 2.0.0 examples tfrecord](https://www.tensorflow.org/tutorials/load_data/tfrecord) <br>\n",
    "& <br>\n",
    "[tutorials load_data images](https://www.tensorflow.org/tutorials/load_data/images) <br>\n",
    "& <br>\n",
    "[tfrecord and tfexample](https://www.tensorflow.org/tutorials/load_data/tfrecord) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t_start_all = time.time()\n",
    "import os\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible data type.\n",
    "    feature = {'feature0': _int64_feature(feature0),\n",
    "               'feature1': _int64_feature(feature1),\n",
    "               'feature2': _bytes_feature(feature2),\n",
    "               'feature3': _float_feature(feature3), }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "# usage examples\n",
    "print(_bytes_feature(b'test_string'))\n",
    "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
    "\n",
    "print(_float_feature(np.exp(1)))\n",
    "\n",
    "print(_int64_feature(True))\n",
    "print(_int64_feature(1))\n",
    "\n",
    "feature = _float_feature(np.exp(1))\n",
    "\n",
    "feature.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_observation = []\n",
    "\n",
    "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data set\n",
    "# The number of observations in the dataset.\n",
    "n_observations = int(1e4)\n",
    "\n",
    "# Boolean feature, encoded as False or True.\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "\n",
    "# Integer feature, random from 0 to 4.\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "\n",
    "# String feature\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "\n",
    "# Float feature, from a standard normal distribution\n",
    "feature3 = np.random.randn(n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the message:\n",
    "example_proto = tf.train.Example.FromString(serialized_example)\n",
    "example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example observation from the dataset.\n",
    "\n",
    "example_observation = []\n",
    "\n",
    "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_proto = tf.train.Example.FromString(serialized_example)\n",
    "example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\n",
    "features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `take(1)` to only pull one example from the dataset.\n",
    "for f0,f1,f2,f3 in features_dataset.take(1):\n",
    "    print(f0)\n",
    "    print(f1)\n",
    "    print(f2)\n",
    "    print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(f0,f1,f2,f3):\n",
    "    tf_string = tf.py_function(serialize_example,\n",
    "                               (f0,f1,f2,f3),  # pass these args to the above function.\n",
    "                               tf.string)      # the return type is `tf.string`.\n",
    "    \n",
    "    return tf.reshape(tf_string, ()) # The result is a scalar\n",
    "\n",
    "tf_serialize_example(f0,f1,f2,f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
    "serialized_features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for features in features_dataset:\n",
    "        yield serialize_example(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_features_dataset = tf.data.Dataset.from_generator(generator, output_types=tf.string, output_shapes=())\n",
    "serialized_features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test.tfrecord' in os.listdir():\n",
    "    print('Halellujah!')\n",
    "else:\n",
    "    print('No No No!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.tfrecord'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(serialized_features_dataset)\n",
    "\n",
    "if 'test.tfrecord' in os.listdir():\n",
    "    print('Halellujah!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_record in raw_dataset.take(5):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parsed_record in parsed_dataset.take(5):\n",
    "    print(repr(parsed_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenameII = 'test2.tfrecord'\n",
    "# Write the `tf.Example` observations to the file.\n",
    "with tf.io.TFRecordWriter(filenameII) as writer:\n",
    "    for i in range(n_observations):\n",
    "        example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filenameII in os.listdir():\n",
    "    print('Halellujah!')\n",
    "else:\n",
    "    print('Boo Hoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh {filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamesII = [filenameII]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenamesII)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_record in raw_dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras:\n",
    "[same page as above but at the bottom](https://www.tensorflow.org/tutorials/load_data/tfrecord) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_in_snow = tf.keras.utils.get_file('320px-Felis_catus-cat_on_snow.jpg', \n",
    " 'https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg')\n",
    "\n",
    "williamsburg_bridge = tf.keras.utils.get_file('194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg',\n",
    "'https://storage.googleapis.com/download.tensorflow.org/example_images/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display(display.Image(filename=cat_in_snow))\n",
    "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display(display.Image(filename=williamsburg_bridge))\n",
    "display.display(display.HTML('<a \"href=https://commons.wikimedia.org/wiki/File:New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg\">From Wikimedia</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = {\n",
    "    cat_in_snow : 0,\n",
    "    williamsburg_bridge : 1,\n",
    "}\n",
    "\n",
    "# This is an example, just using the cat image.\n",
    "image_string = open(cat_in_snow, 'rb').read()\n",
    "\n",
    "label = image_labels[cat_in_snow]\n",
    "\n",
    "# Create a dictionary with features that may be relevant.\n",
    "def image_example(image_string, label):\n",
    "    image_shape = tf.image.decode_jpeg(image_string).shape\n",
    "\n",
    "    feature = {'height': _int64_feature(image_shape[0]),\n",
    "                'width': _int64_feature(image_shape[1]),\n",
    "                'depth': _int64_feature(image_shape[2]),\n",
    "                'label': _int64_feature(label),\n",
    "                'image_raw': _bytes_feature(image_string), }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "for line in str(image_example(image_string, label)).split('\\n')[:15]:\n",
    "    print(line)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the raw image files to `images.tfrecords`.\n",
    "# First, process the two images into `tf.Example` messages.\n",
    "# Then, write to a `.tfrecords` file.\n",
    "record_file = 'images.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for filename, label in image_labels.items():\n",
    "        image_string = open(filename, 'rb').read()\n",
    "        tf_example = image_example(image_string, label)\n",
    "        writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file = 'images.tfrecords'\n",
    "!du -sh {record_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image_dataset = tf.data.TFRecordDataset('images.tfrecords')\n",
    "\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {   'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "                                'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "                                'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "                                'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                                'image_raw': tf.io.FixedLenFeature([], tf.string), }\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_features in parsed_image_dataset:\n",
    "    image_raw = image_features['image_raw'].numpy()\n",
    "    display.display(display.Image(data=image_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tensorflow images](https://www.tensorflow.org/tutorials/load_data/images) <br>\n",
    "```python\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "\n",
    "for image_path in roses[:3]:\n",
    "    display.display(Image.open(str(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = list(CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(train_data_gen)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == CLASS_NAMES\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "\"\"\"\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = 2\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "for image, label in labeled_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(labeled_ds)\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "default_timeit_steps = 1000\n",
    "\n",
    "def timeit(ds, steps=default_timeit_steps):\n",
    "    start = time.time()\n",
    "    it = iter(ds)\n",
    "    for i in range(steps):\n",
    "        batch = next(it)\n",
    "        if i%10 == 0:\n",
    "            print('.',end='')\n",
    "    print()\n",
    "    end = time.time()\n",
    "\n",
    "    duration = end-start\n",
    "    print(\"{} batches: {} s\".format(steps, duration))\n",
    "    print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `keras.preprocessing`\n",
    "\"\"\"\n",
    "....................................................................................................\n",
    "1000 batches: 54.27980279922485 s\n",
    "589.53788 Images/s\n",
    "\"\"\"\n",
    "# timeit(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `tf.data`\n",
    "\"\"\"\n",
    "....................................................................................................\n",
    "1000 batches: 6.2362449169158936 s\n",
    "5131.29302 Images/s\n",
    "\"\"\"\n",
    "# timeit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "....................................................................................................\n",
    "1000 batches: 14.264580011367798 s\n",
    "2243.31876 Images/s\n",
    "\"\"\"\n",
    "# filecache_ds = prepare_for_training(labeled_ds, cache=\"./flowers.tfcache\")\n",
    "# timeit(filecache_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfrecord & tfexample\n",
    "[tfrecord and tfexample](https://www.tensorflow.org/tutorials/load_data/tfrecord) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                    authoritatively crashed by keras -- ssl certificate\n",
    "\"\"\"\n",
    "total_time_all_cells_to_here = time.time() - t_start_all\n",
    "print('total_time_all_cells_to_here', total_time_all_cells_to_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
