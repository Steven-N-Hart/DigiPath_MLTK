{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openslide\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "py_src_code_dir = '../src/python'\n",
    "sys.path.insert(0, py_src_code_dir)\n",
    "from digipath_toolkit import get_sample_selection_mask, get_strided_fence_array\n",
    "from digipath_toolkit import get_patch_location_array_for_image_level\n",
    "\n",
    "data_dir = '../../DigiPath_MLTK_data'\n",
    "zip_tank = '../../DigiPath_MLTK_data/zipTank/wsi_annotation_sample/'\n",
    "xml_name = os.path.join(zip_tank, 'e39a8d60a56844d695e9579bce8f0335.xml')\n",
    "c_lab_id_fn = os.path.join(zip_tank, 'class_label_id.csv')\n",
    "\n",
    "im_dir = '../../DigiPath_MLTK_data/RegistrationDevData'\n",
    "im_file = 'e39a8d60a56844d695e9579bce8f0335.tiff'\n",
    "image_file_name = os.path.join(im_dir, im_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Annotation: labeled patches from .xml, .csv, .svs\n",
    "(and display all for developer sanity check)\n",
    "\n",
    "## Convert xml & csv input to a region_id dict\n",
    "\n",
    "## Create heirarchical mask set from the region_id dict\n",
    "\n",
    "## Write labeled patches from the heirarchical mask set\n",
    "\n",
    "```text\n",
    "Questions:\n",
    "    We should still create a threshold mask as before to omit any blank areas included in an annotation?\n",
    "    Yes.\n",
    " \n",
    "    When an entire label is eclipsed by a higher priority label (Empty) should the function issue a warning?\n",
    "    No.\n",
    " \n",
    "    The TFRecord could now have more than one “class_label” and,\n",
    "    the “label” field that TFRecord owns is still just a sequence number… \n",
    "    thus it may be more difficult to select training/test subsets.\n",
    "    Ergo: should each “class_label” aka “class_label_text” be in a different TFRecord file?\n",
    "    No - one file is fine\n",
    "```\n",
    "\n",
    "## Givin a WSI, an Annotation File and an Annotation Labels priority dictionary file\n",
    "\n",
    "1) Annotation file must follow the QuPath Annotation convention. <br>\n",
    "2) Labels dictionary required to assign priority. <br>\n",
    "****\n",
    "```python\n",
    "# read the Annotation File and the labels priority dict into a regions dictionary:\n",
    "# read the regions dictionary into a labels dict\n",
    "#    for each label\n",
    "#        get the mask,\n",
    "#        add the patches to the tfrecord or write the files,\n",
    "\n",
    "```\n",
    "\n",
    "### Issue: thumbnail_divisor too large makes patch test smaller than one pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from xml.dom import minidom\n",
    "\n",
    "import openslide\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\"\"\"\n",
    "MIN_PATCH_SIZE = 3\n",
    "\n",
    "def get_labels_dict(class_labels_id_file_name):\n",
    "    \"\"\" labels_dict = get_labels_dict(class_labels_id) \n",
    "    Args:\n",
    "        class_labels_id_file_name:  .csv file with columns [Label, ID, Priority]\n",
    "    Returns:\n",
    "        labels_dict:                python dict of dicts:\n",
    "                                        {label_id_(n): {ID: x, Priority: y}, ...}\n",
    "    \"\"\"\n",
    "    # allocate dict of dicts\n",
    "    labels_dict = defaultdict(dict)\n",
    "    \n",
    "    # read the file\n",
    "    lines = ''\n",
    "    try:        \n",
    "        with open(class_labels_id_file_name, 'r') as fh:\n",
    "            lines = fh.readlines()\n",
    "    except:\n",
    "        print('failed opening: ', class_labels_id_file_name)\n",
    "        lines = ''\n",
    "        pass\n",
    "    \n",
    "    # read the lines into the dict\n",
    "    if len(lines) > 0:\n",
    "        for line in lines:\n",
    "            line_list = line.strip().split(',')\n",
    "            if len(line_list) > 1 and line_list[0] != 'Label':\n",
    "                labels_dict[line_list[0]] = {'ID': line_list[1], 'Priority': line_list[1]}\n",
    "                \n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def get_xml_list_of_dicts(xml_file_name):\n",
    "    \"\"\" regions_list = get_xml_list_of_dicts(xml_file_name) \n",
    "    Args:\n",
    "        xml_file_name:  required TagName\n",
    "                            Vertex\n",
    "                        required Attributes\n",
    "                            Id\n",
    "                            Text\n",
    "                            Type\n",
    "                            GeoShape\n",
    "    Returns:\n",
    "        regions_list:   list of dicts with keys:\n",
    "                            region_Id\n",
    "                            class_label_text\n",
    "                            class_label_Id\n",
    "                            region_geo_shape\n",
    "                            coords\n",
    "    \"\"\"\n",
    "    \n",
    "    xml_obj = minidom.parse(xml_file_name)\n",
    "    regions_dom = xml_obj.getElementsByTagName(\"Region\")\n",
    "\n",
    "    regions_list = []\n",
    "    for reg_dom in regions_dom:\n",
    "        tmp_dict = {}\n",
    "        vertices = reg_dom.getElementsByTagName(\"Vertex\")\n",
    "        tmp_dict['region_Id'] = reg_dom.getAttribute('Id')\n",
    "        tmp_dict['class_label_text'] = reg_dom.getAttribute('Text')\n",
    "        tmp_dict['class_label_Id'] = reg_dom.getAttribute('Type')\n",
    "        tmp_dict['region_geo_shape'] = reg_dom.getAttribute('GeoShape')\n",
    "        tmp_dict['coords'] = np.zeros((len(vertices), 2))\n",
    "        for i, vertex in enumerate(vertices):\n",
    "            tmp_dict['coords'][i][0] = vertex.attributes['X'].value\n",
    "            tmp_dict['coords'][i][1] = vertex.attributes['Y'].value\n",
    "            \n",
    "        regions_list.append(tmp_dict)\n",
    "        \n",
    "    return regions_list\n",
    "\n",
    "\n",
    "def get_region_Id_dict(xml_file_name, class_labels_id_file_name):\n",
    "    \"\"\" region_id_dict = get_region_Id_dict(xml_file_name, class_labels_id_file_name) \n",
    "    \"\"\"\n",
    "    # read the xml file into a list of dicts\n",
    "    regions_list = get_xml_list_of_dicts(xml_file_name)\n",
    "    \n",
    "    # read the csv file into a dict of dicts Label: {ID: x, Priority: y}\n",
    "    label_dict = get_labels_dict(class_labels_id_file_name)\n",
    "    \n",
    "    # initialize the output dictionary\n",
    "    region_id_dict = defaultdict(dict)\n",
    "    \n",
    "    # enter each region into the output dict\n",
    "    for region_dict in regions_list:\n",
    "        # extract and cast the region Priority from the csv file\n",
    "        region_priority = int(label_dict[region_dict['class_label_text']]['Priority'])\n",
    "        \n",
    "        # construct the rest of the region dict from the xml file\n",
    "        ridic = {'class_label_text': region_dict['class_label_text'], \n",
    "                 'class_label_Id': region_dict['class_label_Id'], \n",
    "                 'Priority': region_priority, \n",
    "                 'region_geo_shape': region_dict['region_geo_shape'], \n",
    "                 'coords': region_dict['coords']}\n",
    "        \n",
    "        region_id_dict[int(region_dict['region_Id'])] = ridic\n",
    "        \n",
    "    return region_id_dict\n",
    "\n",
    "def regions_dict_to_labels_dict(regions_dict):\n",
    "    \"\"\" labels_dict =   regions_dict_to_labels_dict(regions_dict) \n",
    "                        convert a regions_id_dict to a labels dict with data preserved\n",
    "    \n",
    "    Args:\n",
    "        regions_dict:   such as returned by get_region_Id_dict(xml_file, csv_labels)\n",
    "        \n",
    "    Returns:\n",
    "        labels_dict:    same data with labels as keys to list of regions dicts\n",
    "    \"\"\"\n",
    "    labels_dict = defaultdict(list)\n",
    "    for k_reg_id, reg_dict in regions_dict.items():\n",
    "        reg_dict['region_Id'] = k_reg_id\n",
    "        labels_dict[reg_dict['class_label_text']].append(reg_dict)\n",
    "        \n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def regions_dict_to_priority_dict(regions_dict):\n",
    "    \"\"\" priority_dict, priority_list =   regions_dict_to_labels_dict(regions_dict) \n",
    "                        convert a regions_id_dict to a labels dict with data preserved\n",
    "    \n",
    "    Args:\n",
    "        regions_dict:   such as returned by get_region_Id_dict(xml_file, csv_labels)\n",
    "        \n",
    "    Returns:\n",
    "        priority_dict:    same data with labels as keys to list of regions dicts\n",
    "        priority_list:    ordered highest to lowest (largest)\n",
    "    \"\"\"\n",
    "    priority_list = []\n",
    "    priority_dict = defaultdict(list)\n",
    "    for k_reg_id, reg_dict in regions_dict.items():\n",
    "        reg_dict['region_Id'] = k_reg_id\n",
    "        priority_dict[reg_dict['Priority']].append(reg_dict)\n",
    "        priority_list.append(reg_dict['Priority'])\n",
    "        \n",
    "    priority_list = sorted(priority_list, reverse=True)\n",
    "        \n",
    "    return priority_dict, priority_list\n",
    "\n",
    "\n",
    "def get_region_mask(region_coords, thumbnail_divisor, image_dimensions):\n",
    "    \"\"\" mask_im, img = get_region_mask(region_coords, thumbnail_divisor,image_dimensions) \n",
    "    \"\"\"\n",
    "    # scale the region coords with the thumbnail_divisor, \n",
    "    # convert to a list of tuples of type int\n",
    "    xy_list = (region_coords / thumbnail_divisor).astype(np.int).tolist()\n",
    "    xy_list = [(p[0], p[1]) for p in xy_list ]\n",
    "    \n",
    "    # create a (black) thumbnail of the full-size image scaled with the thumbnail_divisor\n",
    "    thumbnail_size = tuple((np.array(image_dimensions)/thumbnail_divisor).astype(np.int))\n",
    "    num_thumb_size = (thumbnail_size[1], thumbnail_size[0])\n",
    "    img = Image.fromarray(np.zeros(num_thumb_size).astype(np.uint8))\n",
    "    \n",
    "    # make it a Pillow Draw and draw the polygon from the list of (x,y) tuples\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.polygon(xy_list, fill=\"white\")\n",
    "    \n",
    "    # create the logical mask for patch selection\n",
    "    #mask_im = np.array(img) > 0\n",
    "    return np.array(img) > 0\n",
    "\n",
    "def get_select_bounds_from_mask(mask_mat, xy='x'):\n",
    "    \"\"\" Usage: start_stop_dict = get_select_bounds_from_mask(mask_mat, xy='x')\n",
    "    find the first and last unmasked row (y) or col (x) in the mask image input mask_mat\n",
    "    \n",
    "    Args:\n",
    "        mask_mat:           2d numpy binary array\n",
    "        xy:                 character x for x axis or y for y axis\n",
    "        \n",
    "    Returns:\n",
    "        start_stop_dict:    {xy+'_start': _start_, xy+'_end': _stop_}\n",
    "        \n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    _start_ = None\n",
    "    _stop_ = None\n",
    "    \n",
    "    # translate input variables\n",
    "    if xy == 'x':\n",
    "        axis = 1\n",
    "        \n",
    "    elif xy == 'y':\n",
    "        axis = 0\n",
    "        \n",
    "    # sum of axis: sum_of_rows is x, axis=1,\n",
    "    sum_of_axis = mask_mat.sum(axis=axis)\n",
    "    current_greater_than = 0\n",
    "    for k in range(sum_of_axis.size):\n",
    "        if sum_of_axis[k] > 0:\n",
    "            current_greater_than = k\n",
    "            if _start_ is None:\n",
    "                _start_ = k\n",
    "    \n",
    "    # set the last row if a first row one more were found to contain ones\n",
    "    if not _start_ is None and current_greater_than > _start_:\n",
    "        _stop_ = current_greater_than\n",
    "    \n",
    "    # cover the all the way to the include all cases\n",
    "    if _start_ is None:\n",
    "        _start_ = 0\n",
    "        \n",
    "    if _stop_ is None:\n",
    "        _stop_ = k\n",
    "        \n",
    "    # name the return values with the expected x, y input\n",
    "    start_stop_dict = {xy+'_start': _start_, xy+'_end': _stop_}\n",
    "    \n",
    "    return start_stop_dict\n",
    "\n",
    "def get_labeled_mask_dict(run_parameters):\n",
    "    \"\"\" Usage: labeled_masks_dict = get_labeled_masks_dict(run_parameters)\n",
    "    Prioritized dictionary for each region defined in the input xml and csv\n",
    "    \n",
    "    {label: patch_selection_mask, ... } \n",
    "    \n",
    "    Args:\n",
    "        run_parameters:             with keys:\n",
    "                                        csv_file_name\n",
    "                                        xml_file_name\n",
    "                                        thumbnail_divisor\n",
    "                                        wsi_filename\n",
    "                                    \n",
    "    Returns:\n",
    "        heirarchical_mask_dict:     {label_1: mask_image, ...}\n",
    "        \n",
    "    \"\"\"  \n",
    "    # define the return variable\n",
    "    labeled_masks_dict = defaultdict(dict)\n",
    "    \n",
    "    # assign local names\n",
    "    csv_file_name = run_parameters['csv_file_name']\n",
    "    xml_file_name = run_parameters['xml_file_name']\n",
    "    thumbnail_divisor = run_parameters['thumbnail_divisor']\n",
    "    patch_select_method = run_parameters['patch_select_method']\n",
    "    wsi_filename = run_parameters['wsi_filename']\n",
    "    patch_height = max(MIN_PATCH_SIZE, run_parameters['patch_height'] // thumbnail_divisor)\n",
    "    patch_width = max(MIN_PATCH_SIZE, run_parameters['patch_width'] // thumbnail_divisor)\n",
    "    if 'patch_stride_fraction' in run_parameters:\n",
    "        patch_stride = run_parameters['patch_stride_fraction']\n",
    "    else:\n",
    "        patch_stride = 1.0\n",
    "    \n",
    "    # get the priority dict and list of what is in it\n",
    "    regions_dict = get_region_Id_dict(xml_file_name, csv_file_name)\n",
    "    priority_dict, priority_list = regions_dict_to_priority_dict(regions_dict)\n",
    "    \n",
    "    #       initialize the priority mask\n",
    "    os_im_obj = openslide.OpenSlide(wsi_filename)\n",
    "    image_dimensions = os_im_obj.dimensions\n",
    "    thumbnail_size = (image_dimensions[0] // thumbnail_divisor, image_dimensions[1] // thumbnail_divisor)\n",
    "    small_im = os_im_obj.get_thumbnail(thumbnail_size)\n",
    "    os_im_obj.close()\n",
    "\n",
    "    higher_priorities_mask = get_sample_selection_mask(small_im, patch_select_method, run_parameters=None)    \n",
    "    \n",
    "    # iterate the priority dict into the heirarchical mask set \n",
    "    # -- subtracting all higher priority masks from the new lower ones\n",
    "    for p in priority_list:\n",
    "        if len(priority_dict[p]) > 1:\n",
    "            print('Dire Warning: More than one label with same Priority')\n",
    "\n",
    "        p_dict = priority_dict[p][0]\n",
    "        label = p_dict['class_label_text']\n",
    "        this_mask = get_region_mask(p_dict['coords'], thumbnail_divisor, image_dimensions)\n",
    "        this_mask = np.logical_and(np.logical_not(higher_priorities_mask), this_mask)\n",
    "        \n",
    "        if this_mask.sum() > 0:\n",
    "            higher_priorities_mask = np.logical_or(this_mask, higher_priorities_mask)\n",
    "            \n",
    "            p_dict['mask_im'] = this_mask\n",
    "            \n",
    "            start_stop_rows = get_select_bounds_from_mask(this_mask, xy='y')\n",
    "            row_start, row_end = start_stop_rows['y_start'], start_stop_rows['y_end']\n",
    "            rows_fence_array = get_strided_fence_array(patch_height, patch_stride, row_start, row_end)\n",
    "            p_dict['rows_fence_array'] = rows_fence_array\n",
    "            p_dict['level_0_rows_fence_array'] = rows_fence_array[:,0] * thumbnail_divisor\n",
    "\n",
    "            start_stop_cols = get_select_bounds_from_mask(this_mask, xy='x')\n",
    "            col_start, col_end = start_stop_cols['x_start'], start_stop_cols['x_end']\n",
    "            cols_fence_array = get_strided_fence_array(patch_width, patch_stride, col_start, col_end)\n",
    "            p_dict['cols_fence_array'] = cols_fence_array\n",
    "            p_dict['level_0_cols_fence_array'] = cols_fence_array[:,0] * thumbnail_divisor\n",
    "\n",
    "            \n",
    "            labeled_masks_dict[label] = p_dict\n",
    "            \n",
    "    return labeled_masks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../DigiPath_MLTK_data'\n",
    "output_dir = '../../DigiPath_MLTK_data/annotation_test/results'\n",
    "if os.path.isdir(output_dir) == False:\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "wsi_file = 'RegistrationDevData/e39a8d60a56844d695e9579bce8f0335.tiff'\n",
    "wsi_file = os.path.join(data_dir, wsi_file)\n",
    "csv_file = 'wsi_annotation_sample/class_label_id.csv'\n",
    "csv_file = os.path.join(data_dir, csv_file)\n",
    "xml_file = 'wsi_annotation_sample/e39a8d60a56844d695e9579bce8f0335.xml'\n",
    "xml_file = os.path.join(data_dir, xml_file)\n",
    "\n",
    "run_parameters = {'method': 'annotations_to_dir', \n",
    "                  'output_dir': output_dir,\n",
    "                  'wsi_filename': wsi_file, \n",
    "                  'csv_file_name': csv_file,\n",
    "                  'xml_file_name': xml_file,\n",
    "                  'thumbnail_divisor': 100, \n",
    "                  'patch_stride_fraction': 1.0, \n",
    "                  'image_level': 1,  \n",
    "                  'patch_height': 224, \n",
    "                  'patch_width': 224, \n",
    "                  'threshold': 0, \n",
    "                  'patch_select_method': 'threshold_rgb2lab', \n",
    "                  'rgb2lab_threshold': 80}\n",
    "\n",
    "label_mask_dict = get_labeled_mask_dict(run_parameters)\n",
    "for label, lbl_dict in label_mask_dict.items():\n",
    "    print(label, type(lbl_dict), type(lbl_dict['mask_im']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "normal <class 'numpy.ndarray'>\n",
    "ink <class 'numpy.ndarray'>\n",
    "offset <class 'numpy.ndarray'>\n",
    "malignant <class 'numpy.ndarray'>\n",
    "Region <class 'numpy.ndarray'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in lbl_dict.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(lbl_dict))\n",
    "rows_fence_arr = lbl_dict['level_0_rows_fence_array']\n",
    "print(type(rows_fence_arr), rows_fence_arr.shape)\n",
    "for idx in range(rows_fence_arr.shape[0] - 1):\n",
    "    print(rows_fence_arr[idx], '\\t', rows_fence_arr[idx+1] - rows_fence_arr[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review-test notebook implemented functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Test function: get_labeled_masks(run_parameters)\n",
    "        \n",
    "        Expected - one labeled mask per priority level unless mask is blank\n",
    "        \n",
    "\"\"\"\n",
    "t0 = time.time()\n",
    "# labeled_masks_dict = get_labeled_masks(run_parameters)\n",
    "labeled_masks_dict = get_labeled_mask_dict(run_parameters)\n",
    "\n",
    "for merge_label, merged_lbl_msk in labeled_masks_dict.items():\n",
    "    if merged_lbl_msk['mask_im'].sum() == 0:\n",
    "        print(merge_label, 'Is Empty Mask')\n",
    "    else:\n",
    "        m_lbl_im = Image.fromarray((merged_lbl_msk['mask_im'].astype(np.uint8) * 255))\n",
    "        print('mask for %s'%(merge_label))\n",
    "        display(m_lbl_im)\n",
    "    \n",
    "print('total run time: %0.3f'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        Test - demo            regions_dict = get_region_Id_dict(xml_name, c_lab_id_fn)\n",
    "\n",
    "        Test - demo            priority_dict, priority_list= regions_dict_to_priority_dict(regions_dict)\n",
    "\n",
    "Note that in this test set (xml, csv) there is only one class label per priority level\n",
    "\"\"\"\n",
    "regions_dict = get_region_Id_dict(xml_name, c_lab_id_fn)\n",
    "priority_dict, priority_list = regions_dict_to_priority_dict(regions_dict)\n",
    "\n",
    "for p in priority_list:\n",
    "    lbl_dict_list = priority_dict[p]\n",
    "    print('\\nPriority:', p, '\\t(%i dictionaries)'%(len(lbl_dict_list)))\n",
    "    for lbl_dict in lbl_dict_list:\n",
    "        for k, v in lbl_dict.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                print('%20s:'%(k), v[0,:])\n",
    "                for v_ix in range(len(v) - 1):\n",
    "                    print('%20s '%(' '), v[v_ix+1,:])\n",
    "            else:\n",
    "                print('%20s:'%(k), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        n_pixels_per_stride = patch_size * patch_stride\n",
    "        patch_stride = n_pixels_per_stride / patch_size\n",
    "\"\"\"\n",
    "_MIN_STRIDE_PIXELS = 3\n",
    "_patch_stride = 0.1\n",
    "_patch_width = _patch_height = 224\n",
    "\n",
    "#       assure minimum stride s.t. arrays advance by at least MIN_STRIDE_PIXELS\n",
    "_patch_stride = max(_patch_stride, (_MIN_STRIDE_PIXELS / min(_patch_width, _patch_height) ) )\n",
    "print(_patch_stride, _patch_stride * min(_patch_width, _patch_height) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
