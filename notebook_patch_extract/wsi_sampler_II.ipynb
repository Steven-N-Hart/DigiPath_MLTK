{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy image: cleaning, segmentation, etc.\n",
    "[API Reference: scikit-image](https://scikit-image.org/docs/dev/api/api.html) <br>\n",
    "****\n",
    "[Home: scikit-image aka skimage](https://scikit-image.org/) <br>\n",
    "[Documentation: scikit-image](https://scikit-image.org/docs/stable/) <br>\n",
    "[scikit-image on GitHub](https://github.com/scikit-image/scikit-image) <br>\n",
    "[User Guide: scikit-image](https://scikit-image.org/docs/dev/user_guide) <br>\n",
    "[Founder-tutor](https://bids.berkeley.edu/resources/videos/scikit-image-image-analysis-python-intermediate) <br>\n",
    "****\n",
    "## OpenSlide:\n",
    "[OpenSlide Wiki](https://github.com/openslide/openslide/wiki) <br>\n",
    "[OpenSlide api](https://openslide.org/api/python/) <br>\n",
    "[openslide github](https://github.com/openslide/openslide-python) <br>\n",
    "[openslide dot org](https://openslide.org/) <br>\n",
    "[openslide C docs](https://openslide.org/api/openslide_8h.html) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with file: ../../DigiPath_MLTK_data/Aperio/CMU-1-Small-Region.svs \n",
      "Output path: ../../DigiPath_MLTK_data/out_to_test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import openslide\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "output_dir = '../../DigiPath_MLTK_data/out_to_test'\n",
    "if os.path.isdir(output_dir) == False:\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "OUTPUT_PATH = output_dir\n",
    "data_dir = '../../DigiPath_MLTK_data/Aperio'\n",
    "files_list = ['CMU-1-Small-Region.svs', 'CMU-1.svs']\n",
    "SVS = os.path.join(data_dir, files_list[0])\n",
    "print('Working with file:', SVS, '\\nOutput path:', OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "out_dir = '../../DigiPath_MLTK_data/out_to_test'\n",
    "file_types = ['.jpg']\n",
    "files_list = []\n",
    "for maybe_file in os.listdir(out_dir):\n",
    "    full_path = os.path.join(out_dir, maybe_file)\n",
    "    if os.path.isfile(full_path):\n",
    "        _, f_ext = os.path.splitext(maybe_file)\n",
    "        if f_ext in file_types:\n",
    "            files_list.append(full_path)\n",
    "\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Image file: \n",
      "\t../../DigiPath_MLTK_data/Aperio/CMU-1.svs\n",
      "\n",
      "Image is 46000 x 32914\n",
      "1514044000 pixels\n",
      "2875 2057\n",
      "16.0 16.000972289742343\n",
      "obj.level_downsamples (1.0, 4.000121536217793, 16.00048614487117)\n",
      "\n",
      "design phase 0.016112089157104492\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "need to know what size the pre-trained models used\n",
    "& graphic file types preferred by tensorflow (float, float32, int, etc)\n",
    "\"\"\"\n",
    "t0 = time.time()\n",
    "# open the file\n",
    "test_file_name = os.path.join(data_dir, 'CMU-1.svs')\n",
    "print('Opening Image file: \\n\\t{}\\n'.format(test_file_name))\n",
    "os_obj = openslide.OpenSlide(test_file_name)\n",
    "pixels_height = os_obj.dimensions[0]\n",
    "pixels_width = os_obj.dimensions[1]\n",
    "print('Image is {} x {}\\n{} pixels'.format(pixels_height, pixels_width, pixels_height * pixels_width))\n",
    "\n",
    "# read the meta data\n",
    "pixels_height_ds = os_obj.level_dimensions[-1][0]\n",
    "pixels_width_ds = os_obj.level_dimensions[-1][1]\n",
    "print(pixels_height_ds, pixels_width_ds)\n",
    "\n",
    "# find the thumbnail size ratio (need pre-trained size)\n",
    "print(pixels_height / pixels_height_ds, pixels_width / pixels_width_ds)\n",
    "print('obj.level_downsamples', os_obj.level_downsamples)\n",
    "# make the mask / grid\n",
    "\n",
    "# make the directory\n",
    "\n",
    "# get the ndarrays of full size grid, write as type\n",
    "\n",
    "# (save a list of files)\n",
    "\n",
    "print('\\ndesign phase', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on OpenSlide in module openslide object:\n",
      "\n",
      "class OpenSlide(AbstractSlide)\n",
      " |  OpenSlide(filename)\n",
      " |  \n",
      " |  An open whole-slide image.\n",
      " |  \n",
      " |  close() is called automatically when the object is deleted.\n",
      " |  The object may be used as a context manager, in which case it will be\n",
      " |  closed upon exiting the context.\n",
      " |  \n",
      " |  If an operation fails, OpenSlideError is raised.  Note that OpenSlide\n",
      " |  has latching error semantics: once OpenSlideError is raised, all future\n",
      " |  operations on the OpenSlide object, other than close(), will fail.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OpenSlide\n",
      " |      AbstractSlide\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filename)\n",
      " |      Open a whole-slide image.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close the OpenSlide object.\n",
      " |  \n",
      " |  get_best_level_for_downsample(self, downsample)\n",
      " |      Return the best level for displaying the given downsample.\n",
      " |  \n",
      " |  read_region(self, location, level, size)\n",
      " |      Return a PIL.Image containing the contents of the region.\n",
      " |      \n",
      " |      location: (x, y) tuple giving the top left pixel in the level 0\n",
      " |                reference frame.\n",
      " |      level:    the level number.\n",
      " |      size:     (width, height) tuple giving the region size.\n",
      " |      \n",
      " |      Unlike in the C interface, the image data returned by this\n",
      " |      function is not premultiplied.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  detect_format(filename) from builtins.type\n",
      " |      Return a string describing the format vendor of the specified file.\n",
      " |      \n",
      " |      If the file format is not recognized, return None.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  associated_images\n",
      " |      Images associated with this whole-slide image.\n",
      " |      \n",
      " |      This is a map: image name -> PIL.Image.\n",
      " |      \n",
      " |      Unlike in the C interface, the images accessible via this property\n",
      " |      are not premultiplied.\n",
      " |  \n",
      " |  level_count\n",
      " |      The number of levels in the image.\n",
      " |  \n",
      " |  level_dimensions\n",
      " |      A list of (width, height) tuples, one for each level of the image.\n",
      " |      \n",
      " |      level_dimensions[n] contains the dimensions of level n.\n",
      " |  \n",
      " |  level_downsamples\n",
      " |      A list of downsampling factors for each level of the image.\n",
      " |      \n",
      " |      level_downsample[n] contains the downsample factor of level n.\n",
      " |  \n",
      " |  properties\n",
      " |      Metadata about the image.\n",
      " |      \n",
      " |      This is a map: property name -> property value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from AbstractSlide:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_val, exc_tb)\n",
      " |  \n",
      " |  get_thumbnail(self, size)\n",
      " |      Return a PIL.Image containing an RGB thumbnail of the image.\n",
      " |      \n",
      " |      size:     the maximum size of the thumbnail.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from AbstractSlide:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  dimensions\n",
      " |      A (width, height) tuple for level 0 of the image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(os_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "MAXPATCHESTOWRITE = 1000\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import openslide\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def get_thumbnail(img, x_level0, y_level0, patch_size, output_path):\n",
    "    patch = img.read_region((x_level0, y_level0), 0, (patch_size, patch_size))\n",
    "    patch = patch.convert('RGB')\n",
    "    fname = img.properties['aperio.Filename'].replace(' ', '_')\n",
    "    fname += '_' + str(x_level0)\n",
    "    fname += '_' + str(y_level0)\n",
    "    fname += '_' + '0'\n",
    "    fname += '_' + str(patch_size)\n",
    "    fname += '.jpg'\n",
    "    patch_arr = np.array(patch.convert('L'))\n",
    "    if np.average(patch_arr) < 230:\n",
    "        global num_patches\n",
    "        num_patches += 1\n",
    "        patch.save(os.path.join(output_path, fname))\n",
    "\n",
    "def process_svs(SVS,\n",
    "                normalization_factor=1000,\n",
    "                patch_size=512,\n",
    "                buffer=10,\n",
    "                output_path=OUTPUT_PATH):\n",
    "    img = openslide.OpenSlide(SVS)\n",
    "\n",
    "    global num_patches\n",
    "    num_patches = 0\n",
    "\n",
    "    x_max, y_max = img.dimensions\n",
    "    thumbnail = img.get_thumbnail((normalization_factor, normalization_factor))\n",
    "\n",
    "    grey_thumbnail = np.array(thumbnail.convert(\"L\"))\n",
    "    thresh = threshold_otsu(grey_thumbnail)\n",
    "    mask = np.array(grey_thumbnail) < thresh\n",
    "\n",
    "    # how many pixels in the raw image per pixel in mask\n",
    "    x_num_orgPix_per_thumbPix = math.ceil(x_max / mask.shape[0])\n",
    "    y_num_orgPix_per_thumbPix = math.ceil(y_max / mask.shape[1])\n",
    "    # print(x_num_orgPix_per_thumbPix, y_num_orgPix_per_thumbPix)\n",
    "\n",
    "    # Find out how many pixels in image mask to count as a patch in original\n",
    "    num_x_mask_pixels_per_rawPatch = math.ceil(patch_size / x_num_orgPix_per_thumbPix)\n",
    "    num_y_mask_pixels_per_rawPatch = math.ceil(patch_size / y_num_orgPix_per_thumbPix)\n",
    "    # print(num_x_mask_pixels_per_rawPatch, num_y_mask_pixels_per_rawPatch)\n",
    "\n",
    "    mask_x, mask_y = mask.shape\n",
    "    x_mask_prev = 0\n",
    "\n",
    "    # Iterate through the mask to identify positive pixels\n",
    "    for x in range(buffer, mask_x - buffer):\n",
    "        x_mask_window = x + num_x_mask_pixels_per_rawPatch\n",
    "        if x_mask_window <= x_mask_prev:\n",
    "            continue\n",
    "        y_mask_prev = 0\n",
    "        for y in range(buffer, mask_y - buffer):\n",
    "            y_mask_window = y + num_y_mask_pixels_per_rawPatch\n",
    "            # print('Evaluate: {} {} & {}'.format(y, y_mask_window, y_mask_prev))\n",
    "            if y_mask_window <= y_mask_prev:\n",
    "                continue\n",
    "            if y % 100 == 0:\n",
    "                print('X: {}\\tY:{} of {} with total of {} so far'.format(x, y, \n",
    "                                                                         mask.shape, \n",
    "                                                                         num_patches), end='\\r',\n",
    "                                                                  flush=True)\n",
    "                \n",
    "            if np.sum(mask[x:x_mask_window, y:y_mask_window]) > 0:\n",
    "                # convert mask coordinates to level0 coordinates\n",
    "                x_level0 = x * x_num_orgPix_per_thumbPix\n",
    "                y_level0 = y * y_num_orgPix_per_thumbPix\n",
    "                get_thumbnail(img, x_level0, y_level0, patch_size, output_path)\n",
    "                \n",
    "                #                                      <0><0>          Limit number of files\n",
    "                if num_patches >= MAXPATCHESTOWRITE:\n",
    "                    print('\\n\\n\\t{} num_patched out\\n\\n'.format(num_patches))\n",
    "                    return\n",
    "                #                                      <0><0>\n",
    "\n",
    "            # print('yamsk windoe: {}'.format(y_mask_window))\n",
    "            y_mask_prev = y_mask_window\n",
    "        x_mask_prev = x_mask_window\n",
    "\n",
    "    print('Printed {} from {}'.format(num_patches, SVS))\n",
    "\n",
    "num_patches = 0\n",
    "\"\"\"\n",
    "# if __name__ == '__main__':\n",
    "#     for SVS in glob.glob('/data/biliary/svs/negative/*svs'):\n",
    "#         process_svs(SVS)\n",
    "\"\"\"\n",
    "print('processing: {}'.format(SVS))\n",
    "process_svs(SVS)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
